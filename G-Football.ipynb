{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"G-Football.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyObM87QDa54N6bieOT0geTL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"JezRCSzQzmyy"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"AwiPWSjbujSz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649417913018,"user_tz":-180,"elapsed":57369,"user":{"displayName":"george mouts","userId":"12301814581979843830"}},"outputId":"1f56909f-ad37-41c8-a5bf-7f6db9625099"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'kaggle-environments' already exists and is not an empty directory.\n","Processing /content/kaggle-environments\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.7) (4.3.3)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.7) (1.1.4)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.7) (1.21.5)\n","Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.7) (2.27.1)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (1.0.1)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (7.1.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (2.11.3)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (1.1.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.2->kaggle-environments==1.9.7) (2.0.1)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (5.4.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (21.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (3.10.0.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (4.11.3)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.1->kaggle-environments==1.9.7) (3.7.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (1.24.3)\n","Building wheels for collected packages: kaggle-environments\n","  Building wheel for kaggle-environments (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle-environments: filename=kaggle_environments-1.9.7-py3-none-any.whl size=1813045 sha256=b633bd9102343a6c59e794d902099c1d6aa7266bfe15928adf5cd66bbb015075\n","  Stored in directory: /root/.cache/pip/wheels/67/f1/54/59176bd30840c0a045df67632e2e903095b3c02b64cb0a636c\n","Successfully built kaggle-environments\n","Installing collected packages: kaggle-environments\n","  Attempting uninstall: kaggle-environments\n","    Found existing installation: kaggle-environments 1.9.7\n","    Uninstalling kaggle-environments-1.9.7:\n","      Successfully uninstalled kaggle-environments-1.9.7\n","Successfully installed kaggle-environments-1.9.7\n","Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Fetched 252 kB in 9s (28.1 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","libsdl2-gfx-dev is already the newest version (1.0.4+dfsg-1).\n","libsdl2-ttf-dev is already the newest version (2.0.14+dfsg1-2).\n","0 upgraded, 0 newly installed, 0 to remove and 96 not upgraded.\n","fatal: destination path 'football' already exists and is not an empty directory.\n","--2022-04-08 11:38:00--  https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.8.so\n","Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.211.128, 108.177.12.128, 108.177.13.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.211.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 45403632 (43M) [application/octet-stream]\n","Saving to: ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’\n","\n","football/third_part 100%[===================>]  43.30M   179MB/s    in 0.2s    \n","\n","2022-04-08 11:38:00 (179 MB/s) - ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’ saved [45403632/45403632]\n","\n","Processing /content/football\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: pygame==1.9.6 in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (1.9.6)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (4.1.2.30)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (1.4.1)\n","Requirement already satisfied: gym>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (0.17.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (1.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (0.37.1)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.3.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.5.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.21.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.11.0->gfootball==2.8) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->gfootball==2.8) (1.15.0)\n","Building wheels for collected packages: gfootball\n","  Building wheel for gfootball (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gfootball: filename=gfootball-2.8-cp37-cp37m-linux_x86_64.whl size=38781744 sha256=8e0fc9150174dee3e5aabdad2d5a76bc7d902bb8bb07ba002074f71e09388cd2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-dgsoyh8n/wheels/bb/c2/92/82a23d0c207f5497a23f4316675eb1629e6be474bd2c3be61a\n","Successfully built gfootball\n","Installing collected packages: gfootball\n","  Attempting uninstall: gfootball\n","    Found existing installation: gfootball 2.8\n","    Uninstalling gfootball-2.8:\n","      Successfully uninstalled gfootball-2.8\n","Successfully installed gfootball-2.8\n"]}],"source":["#https://www.kaggle.com/piotrstanczyk/gfootball-template-bot  G-FOOTBALL TEMPLATE BOT\n","# Install:\n","# Kaggle environments.\n","!git clone https://github.com/Kaggle/kaggle-environments.git\n","!cd kaggle-environments && pip install .\n","\n","# GFootball environment.\n","!apt-get update -y\n","!apt-get install -y libsdl2-gfx-dev libsdl2-ttf-dev\n","\n","# Make sure that the Branch in git clone and in wget call matches !!\n","!git clone -b v2.8 https://github.com/google-research/football.git\n","!mkdir -p football/third_party/gfootball_engine/lib\n","\n","!wget https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.8.so -O football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so\n","!cd football && GFOOTBALL_USE_PREBUILT_SO=1 pip3 install ."]},{"cell_type":"markdown","source":["# All the imports"],"metadata":{"id":"WVKirdPZ7joO"}},{"cell_type":"code","source":["from gfootball.env.football_env import FootballEnv\n","from kaggle_environments import make\n","from gfootball.env.config import Config\n","from gfootball.env.football_env import FootballEnv\n","\n","#import dqn libraries\n","import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim \n","import numpy as np\n","import pandas as pd\n","import itertools\n","import random\n","from collections import deque\n","import matplotlib.pyplot as plt\n","\n","#import env \n","import gym\n","import gfootball \n","\n","#env_name = \"GFootballBase-v0\"\n","#print(env_name)"],"metadata":{"id":"Y8iVn65JzVqw","executionInfo":{"status":"ok","timestamp":1649417973395,"user_tz":-180,"elapsed":6,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["# Initialize variables"],"metadata":{"id":"6DnksAK4BzPW"}},{"cell_type":"code","source":["BUFFERSIZE = 100000  #how many experiences will store |ReplayBufferSize=100,000\n","REWBUFFERSIZE = 100   #how many episode rewards will store|RewardBufferSize =100\n","MINREPLAYSIZE= 3000 # Episode is 3000 steps\n","GAMMA = 0.04\n","EPSILON =0.03\n","TARGET_UPDATE_FREQ = 25\n","\n","EPSILON_START=0.5\n","EPSILON_END =0.01\n","EPSILON_DECAY=0.001\n","\n","BATCH_SIZE = 3\n"],"metadata":{"id":"Q1ygyd2KEjM2","executionInfo":{"status":"ok","timestamp":1649417975776,"user_tz":-180,"elapsed":261,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["# Deep Q Network Model"],"metadata":{"id":"xTTdFh2aEFjF"}},{"cell_type":"code","source":["class DQN(nn.Module):\n","  def __init__(self,env):\n","    super(DQN,self).__init__()\n","    input_dims = int(np.prod(env.observation_space.shape)) #neurons input layer = number of observations\n","    self.net =nn.Sequential(nn.Linear(input_dims,250), \n","                            nn.Tanh(),\n","                            nn.Linear(250,env.action_space.n)) # neurons outpul layer = number of observations \n","                            \n","  def forward(self,x):\n","    return self.net(x) #use the dqnetwork\n","\n","  def act(self,obs): #returns the best acrtion/highest value action of the net \n","    obs_t =torch.as_tensor(obs,dtype=torch.float32)\n","    q_values=self(obs_t.unsqueeze(0)) # make tensor a batch dimension\n","\n","    max_q_index = torch.argmax(q_values,dim=1)[0]   # taking action with highest q value\n","    action = max_q_index.detach().item() # making tensor to integer which represents action \n","    \n","    return action \n","\n"],"metadata":{"id":"to44sPKhEETf","executionInfo":{"status":"ok","timestamp":1649417978698,"user_tz":-180,"elapsed":407,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["# Agent "],"metadata":{"id":"Elknm2VGEhMX"}},{"cell_type":"code","source":["class Agent() : \n","  def __init__(self,gamma,epsilon):\n","    self.gamma =gamma\n","    self.epsilon =epsilon\n","    \n","    self.ReplayBuffer = deque(maxlen=BUFFERSIZE) #Store experiences \n","    self.RewBuffer = deque(maxlen=REWBUFFERSIZE) #Store rewards\n","    \n","    self.online_net = DQN(env)   \n","    self.target_net = DQN(env)  \n","\n","    self.target_net.load_state_dict(self.online_net.state_dict())\n","\n","\n","  def transition(self,obs,new_obs,action,reward ,done): # should be tuple ? \n","    self.obs =obs\n","    self.action=action\n","    self.reward =reward \n","    self.done=done\n","    #self.info =info\n","    self.new_obs =new_obs\n","    TransitionTuple= (obs,new_obs,action,reward,done)\n","    #print(\"class\",TransitionTuple)\n","    return TransitionTuple\n","\n","  def learn(self,loss):\n","    \n","    self.loss=loss\n","    self.optimizer=torch.optim.Adam(self.online_net.parameters(),lr =1e-3) \n","    self.optimizer.zero_grad()\n","    self.loss.backward()\n","    self.optimizer.step()\n","\n","  def Arrays_To_Tensors(self,transitions): #make arrays -> pytorch tensors\n","    self.transitions=transitions\n","\n","    #Store observations as arrays\n","    obses = np.asarray([t[0] for t in transitions])\n","    new_obses = np.asarray([t[1]for t in transitions])\n","    actions = np.asarray([t[2] for t in transitions])\n","    rewards = np.asarray([t[3] for t in transitions])\n","    dones = np.asarray([t[4] for t in transitions])\n","  \n","    #Convert observation arrays to pytorch tensors\n","    obses_t=torch.as_tensor(obses,dtype=torch.float32)\n","    actions_t = torch.as_tensor(actions,dtype=torch.int64).unsqueeze(-1) #making batch dimension to one dimension\n","    rewards_t = torch.as_tensor(rewards,dtype= torch.float32).unsqueeze(-1)\n","    dones_t = torch.as_tensor(dones,dtype= torch.float32).unsqueeze(-1)\n","    new_obses_t = torch.as_tensor(new_obses,dtype= torch.float32)\n","\n","    return obses_t,actions_t,rewards_t,dones_t,new_obses_t\n","\n","\n"],"metadata":{"id":"1IRll4ZoEi7c","executionInfo":{"status":"ok","timestamp":1649417981603,"user_tz":-180,"elapsed":291,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"knTlNNXLoR_n","executionInfo":{"status":"aborted","timestamp":1649417968438,"user_tz":-180,"elapsed":21,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"I7CxKikMoSgK","executionInfo":{"status":"aborted","timestamp":1649417968438,"user_tz":-180,"elapsed":20,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# All Prints"],"metadata":{"id":"2MA4EXOMYaII"}},{"cell_type":"code","source":["class All_prints():\n","  \n","  def __init___(self,step):\n","    self.step=step\n","    #self.RewBuffer = RewBuffer\n","    self.reward=reward\n","\n","  def printstats(self,step,RewBuffer,eps_reward):  #Kaleitai otan ginei done , diladi otan teleiosei ena paixnidi\n","    self.step=step\n","    self.RewBuffer=RewBuffer\n","    self.eps_reward=eps_reward\n","    print(\"-->Episode:\",self.step%3000 + 1 ,\"\\t\",\"Episode Reward:\",self.eps_reward,\"<--\")\n","    print(\"Step\",step)\n","    print(\"lista apo rewards mexri tora\" ,self.RewBuffer)\n","    print(\"Avg reward\", np.mean(self.RewBuffer))\n","    print(\"---------------------------------------------------\")\n","\n","  def print_who_scored(self, reward):\n","    self.reward=reward\n","    if(self.reward==-1):\n","      print(\"opponent team scored\")\n","    elif(self.reward==1):\n","      print(\"our team scored !!!\")\n"," \n","  def rew_graph(self,RewBuffer,step,num_of_eps):\n","      self.RewBuffer=RewBuffer\n","      self.step=step\n","      self.num_of_eps=num_of_eps\n","      episode=self.step%3000\n","      eps_list=list(range(1,self.num_of_eps+1))#pairnei to proto , den pairnei to teleytaio\n","      #print(agent.RewBuffer,eps_list)\n","      plt.plot(eps_list,self.RewBuffer)\n","      plt.xlabel('Episode')\n","      plt.ylabel('Rewards')\n","      plt.grid(True)\n","      plt.show()"],"metadata":{"id":"9kC3LFnSmkGC","executionInfo":{"status":"ok","timestamp":1649417984606,"user_tz":-180,"elapsed":310,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["# Create Environment -- Main \n"],"metadata":{"id":"ZCAOuUjA8ZpZ"}},{"cell_type":"code","source":["#if __name__ =='main': \n","#TO DO:MAKE A CLASS FOR LEARNING\n","\n","env = gym.make(\"GFootball-11_vs_11_kaggle-simple115v2-v0\") #List with the 115 states \n","eps_reward =0.0\n","\n","obs = env.reset()\n","\n","#CREATE OBJECTS \n","agent=Agent(GAMMA,EPSILON) #Agent class\n","all_prints=All_prints() # print class\n","\n","#Initialize ReplayBuffer # TO DO : MAKE IT A CLASS\n","\n","for i in range(MINREPLAYSIZE): \n","  action =env.action_space.sample() #random action \n","\n","  new_obs ,reward,done ,info = env.step(action) \n","\n","  transition = agent.transition(obs,new_obs,action,reward ,done) #obs ,action ,reward , done ,info , new_obs  PROSEKSE TO MALLON LATHOS\n","  agent.ReplayBuffer.append(transition)  #Fill Replay Buffer with transitions\n","  obs=new_obs\n","\n","  if(done):  \n","    obs=env.reset()\n","\n","\n","# MAIN TRAIN LOOP\n","obs =env.reset()\n","c= 0\n","num_of_eps= 100     #GIVE NUMBER OF EPISODES\n","\n","for step in range((3000 * num_of_eps) + num_of_eps ):# play 3000 steps = 1 match = 1 episode\n","  \n","  \n","  #epsilon greedy\n","  epsilon = np.interp(step,[0,EPSILON_DECAY],[EPSILON_START,EPSILON_END]) #Epsilon start->end with epsilon decays steps from 100% random actions->2% rnd actions\n","  rnd_sample = random.random()\n","  \n","  if rnd_sample <= epsilon: #random action |explore|\n","    action = env.action_space.sample()\n","  else:  \n","    action = agent.online_net.act(obs) #best action |exploit|     YPARXEI THEMA EDO PERA , POU GEMIZEI TO ONLINE NET ??\n"," \n","  \n","  new_obs,reward,done,info = env.step(action)\n","  #print who scored\n","  all_prints.print_who_scored(reward)\n","  transition = agent.transition(obs,new_obs,action,reward ,done) #fill Replaybuffer with transitions \n","  agent.ReplayBuffer.append(transition) \n","  obs=new_obs\n","\n","  eps_reward = eps_reward+reward\n","  \n","  if (done) : \n","    obs=env.reset()  \n","    agent.RewBuffer.append(eps_reward)\n","    #Print Resume when an episode ends\n","    all_prints.printstats(step,agent.RewBuffer,eps_reward)#balto sto rewgraph\n","    if(step == (3000 * num_of_eps)+num_of_eps -1):\n","      all_prints.rew_graph(agent.RewBuffer,step,num_of_eps)\n","    eps_reward =0.0 \n","\n","\n","# Start Gradient Step \n","  transitions =random.sample(agent.ReplayBuffer , BATCH_SIZE) #sample batch_size number of random transitions from Replaybuffer ,\n","                                                              # Replay buffer have been filled earlier\n","\n"," #Store arrays and conver them to pytorch sensors\n","  obses_t,actions_t,rewards_t,dones_t,new_obses_t = agent.Arrays_To_Tensors(transitions)\n","\n","  #Compute Targets\n","  target_q_values = agent.target_net(new_obses_t)# q values for each observation \n","  max_target_q_values = target_q_values.max(dim=1,keepdim=True)[0] #take the maximum value in dim =1 , discard all the rest dimensions\n","                                                                  #max returns tuple , first element is highest values and second is the index to them \n","\n","  targets = rewards_t +GAMMA + (1-dones_t) * max_target_q_values #deepmind_atari_paper dqn learn with replay\n","                                                                #if its a terminal state: dones_t =1 -> targets= rewards_t\n","\n","  #Compute Loss\n","  q_values = agent.online_net(obses_t)\n","  action_q_values =torch.gather(input=q_values,dim=1,index=actions_t)\n","  loss=nn.functional.smooth_l1_loss(action_q_values,targets)\n","\n","  #Gradient Descent \n","  agent.learn(loss)\n","  '''optimizer=torch.optim.Adam(agent.online_net.parameters(),lr =0.02)\n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()'''\n","\n","  #Update the target network, copying all weights and biases in DQN\n","  if step% TARGET_UPDATE_FREQ == 0:   #Update target network based on online network\n","    agent.target_net.load_state_dict(agent.online_net.state_dict())\n","\n","  \n","  \n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Elq8YWsx8d1C","executionInfo":{"status":"ok","timestamp":1649422947521,"user_tz":-180,"elapsed":4959791,"user":{"displayName":"george mouts","userId":"12301814581979843830"}},"outputId":"3adad90f-22c7-46e8-cad4-945bfad450b6"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["opponent team scored\n","-->Episode: 1 \t Episode Reward: -1.0 <--\n","Step 3000\n","lista apo rewards mexri tora deque([-1.0], maxlen=100)\n","Avg reward -1.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 2 \t Episode Reward: -2.0 <--\n","Step 6001\n","lista apo rewards mexri tora deque([-1.0, -2.0], maxlen=100)\n","Avg reward -1.5\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 3 \t Episode Reward: -2.0 <--\n","Step 9002\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0], maxlen=100)\n","Avg reward -1.6666666666666667\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 4 \t Episode Reward: -3.0 <--\n","Step 12003\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0], maxlen=100)\n","Avg reward -2.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 5 \t Episode Reward: -4.0 <--\n","Step 15004\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0], maxlen=100)\n","Avg reward -2.4\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 6 \t Episode Reward: -3.0 <--\n","Step 18005\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0], maxlen=100)\n","Avg reward -2.5\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 7 \t Episode Reward: -2.0 <--\n","Step 21006\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.4285714285714284\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 8 \t Episode Reward: -3.0 <--\n","Step 24007\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0], maxlen=100)\n","Avg reward -2.5\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 9 \t Episode Reward: -1.0 <--\n","Step 27008\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0], maxlen=100)\n","Avg reward -2.3333333333333335\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 10 \t Episode Reward: -4.0 <--\n","Step 30009\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0], maxlen=100)\n","Avg reward -2.5\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 11 \t Episode Reward: -8.0 <--\n","Step 33010\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0], maxlen=100)\n","Avg reward -3.0\n","---------------------------------------------------\n","-->Episode: 12 \t Episode Reward: 0.0 <--\n","Step 36011\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0], maxlen=100)\n","Avg reward -2.75\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 13 \t Episode Reward: -3.0 <--\n","Step 39012\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0], maxlen=100)\n","Avg reward -2.769230769230769\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 14 \t Episode Reward: -3.0 <--\n","Step 42013\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0], maxlen=100)\n","Avg reward -2.7857142857142856\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 15 \t Episode Reward: -5.0 <--\n","Step 45014\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0], maxlen=100)\n","Avg reward -2.933333333333333\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 16 \t Episode Reward: -1.0 <--\n","Step 48015\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0], maxlen=100)\n","Avg reward -2.8125\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 17 \t Episode Reward: -4.0 <--\n","Step 51016\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0], maxlen=100)\n","Avg reward -2.8823529411764706\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 18 \t Episode Reward: -4.0 <--\n","Step 54017\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0], maxlen=100)\n","Avg reward -2.9444444444444446\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 19 \t Episode Reward: -1.0 <--\n","Step 57018\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0], maxlen=100)\n","Avg reward -2.8421052631578947\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 20 \t Episode Reward: -3.0 <--\n","Step 60019\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0], maxlen=100)\n","Avg reward -2.85\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 21 \t Episode Reward: -5.0 <--\n","Step 63020\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0], maxlen=100)\n","Avg reward -2.9523809523809526\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 22 \t Episode Reward: -3.0 <--\n","Step 66021\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0], maxlen=100)\n","Avg reward -2.9545454545454546\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 23 \t Episode Reward: -2.0 <--\n","Step 69022\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.9130434782608696\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 24 \t Episode Reward: -5.0 <--\n","Step 72023\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0], maxlen=100)\n","Avg reward -3.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 25 \t Episode Reward: -4.0 <--\n","Step 75024\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0], maxlen=100)\n","Avg reward -3.04\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 26 \t Episode Reward: -3.0 <--\n","Step 78025\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0], maxlen=100)\n","Avg reward -3.0384615384615383\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 27 \t Episode Reward: -3.0 <--\n","Step 81026\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0], maxlen=100)\n","Avg reward -3.037037037037037\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 28 \t Episode Reward: -4.0 <--\n","Step 84027\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0], maxlen=100)\n","Avg reward -3.0714285714285716\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 29 \t Episode Reward: -1.0 <--\n","Step 87028\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0], maxlen=100)\n","Avg reward -3.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 30 \t Episode Reward: -3.0 <--\n","Step 90029\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0], maxlen=100)\n","Avg reward -3.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 31 \t Episode Reward: -2.0 <--\n","Step 93030\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.967741935483871\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 32 \t Episode Reward: -1.0 <--\n","Step 96031\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0], maxlen=100)\n","Avg reward -2.90625\n","---------------------------------------------------\n","-->Episode: 33 \t Episode Reward: 0.0 <--\n","Step 99032\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0], maxlen=100)\n","Avg reward -2.8181818181818183\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 34 \t Episode Reward: -5.0 <--\n","Step 102033\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0], maxlen=100)\n","Avg reward -2.8823529411764706\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 35 \t Episode Reward: -4.0 <--\n","Step 105034\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0], maxlen=100)\n","Avg reward -2.914285714285714\n","---------------------------------------------------\n","-->Episode: 36 \t Episode Reward: 0.0 <--\n","Step 108035\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0], maxlen=100)\n","Avg reward -2.8333333333333335\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 37 \t Episode Reward: -2.0 <--\n","Step 111036\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0], maxlen=100)\n","Avg reward -2.810810810810811\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 38 \t Episode Reward: -3.0 <--\n","Step 114037\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0], maxlen=100)\n","Avg reward -2.8157894736842106\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 39 \t Episode Reward: -3.0 <--\n","Step 117038\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0], maxlen=100)\n","Avg reward -2.8205128205128207\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 40 \t Episode Reward: -5.0 <--\n","Step 120039\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0], maxlen=100)\n","Avg reward -2.875\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 41 \t Episode Reward: -4.0 <--\n","Step 123040\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0], maxlen=100)\n","Avg reward -2.902439024390244\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 42 \t Episode Reward: -2.0 <--\n","Step 126041\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0], maxlen=100)\n","Avg reward -2.880952380952381\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 43 \t Episode Reward: -6.0 <--\n","Step 129042\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0], maxlen=100)\n","Avg reward -2.953488372093023\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 44 \t Episode Reward: -3.0 <--\n","Step 132043\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0], maxlen=100)\n","Avg reward -2.9545454545454546\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 45 \t Episode Reward: -2.0 <--\n","Step 135044\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.933333333333333\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 46 \t Episode Reward: -3.0 <--\n","Step 138045\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0], maxlen=100)\n","Avg reward -2.9347826086956523\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 47 \t Episode Reward: -3.0 <--\n","Step 141046\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0], maxlen=100)\n","Avg reward -2.9361702127659575\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 48 \t Episode Reward: -3.0 <--\n","Step 144047\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0], maxlen=100)\n","Avg reward -2.9375\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 49 \t Episode Reward: -5.0 <--\n","Step 147048\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0], maxlen=100)\n","Avg reward -2.979591836734694\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 50 \t Episode Reward: -5.0 <--\n","Step 150049\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0], maxlen=100)\n","Avg reward -3.02\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 51 \t Episode Reward: -5.0 <--\n","Step 153050\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0], maxlen=100)\n","Avg reward -3.0588235294117645\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 52 \t Episode Reward: -2.0 <--\n","Step 156051\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0], maxlen=100)\n","Avg reward -3.0384615384615383\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 53 \t Episode Reward: -3.0 <--\n","Step 159052\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0], maxlen=100)\n","Avg reward -3.0377358490566038\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 54 \t Episode Reward: -3.0 <--\n","Step 162053\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0], maxlen=100)\n","Avg reward -3.037037037037037\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 55 \t Episode Reward: -3.0 <--\n","Step 165054\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0], maxlen=100)\n","Avg reward -3.036363636363636\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 56 \t Episode Reward: -1.0 <--\n","Step 168055\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0], maxlen=100)\n","Avg reward -3.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 57 \t Episode Reward: -4.0 <--\n","Step 171056\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0], maxlen=100)\n","Avg reward -3.017543859649123\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 58 \t Episode Reward: -2.0 <--\n","Step 174057\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0], maxlen=100)\n","Avg reward -3.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 59 \t Episode Reward: -3.0 <--\n","Step 177058\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0], maxlen=100)\n","Avg reward -3.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 60 \t Episode Reward: -2.0 <--\n","Step 180059\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.9833333333333334\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 61 \t Episode Reward: -3.0 <--\n","Step 183060\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0], maxlen=100)\n","Avg reward -2.9836065573770494\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 62 \t Episode Reward: -3.0 <--\n","Step 186061\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0], maxlen=100)\n","Avg reward -2.9838709677419355\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 63 \t Episode Reward: -2.0 <--\n","Step 189062\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.9682539682539684\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 64 \t Episode Reward: -4.0 <--\n","Step 192063\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0], maxlen=100)\n","Avg reward -2.984375\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 65 \t Episode Reward: -3.0 <--\n","Step 195064\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0], maxlen=100)\n","Avg reward -2.9846153846153847\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 66 \t Episode Reward: -2.0 <--\n","Step 198065\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.9696969696969697\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 67 \t Episode Reward: -3.0 <--\n","Step 201066\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0], maxlen=100)\n","Avg reward -2.970149253731343\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 68 \t Episode Reward: -3.0 <--\n","Step 204067\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0], maxlen=100)\n","Avg reward -2.9705882352941178\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 69 \t Episode Reward: -2.0 <--\n","Step 207068\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.9565217391304346\n","---------------------------------------------------\n","-->Episode: 70 \t Episode Reward: 0.0 <--\n","Step 210069\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0], maxlen=100)\n","Avg reward -2.914285714285714\n","---------------------------------------------------\n","our team scored !!!\n","opponent team scored\n","-->Episode: 71 \t Episode Reward: 0.0 <--\n","Step 213070\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0], maxlen=100)\n","Avg reward -2.8732394366197185\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 72 \t Episode Reward: -3.0 <--\n","Step 216071\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0], maxlen=100)\n","Avg reward -2.875\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 73 \t Episode Reward: -2.0 <--\n","Step 219072\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.863013698630137\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 74 \t Episode Reward: -2.0 <--\n","Step 222073\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0], maxlen=100)\n","Avg reward -2.8513513513513513\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 75 \t Episode Reward: -4.0 <--\n","Step 225074\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0], maxlen=100)\n","Avg reward -2.8666666666666667\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 76 \t Episode Reward: -3.0 <--\n","Step 228075\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0], maxlen=100)\n","Avg reward -2.8684210526315788\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 77 \t Episode Reward: -2.0 <--\n","Step 231076\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.857142857142857\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 78 \t Episode Reward: -1.0 <--\n","Step 234077\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0], maxlen=100)\n","Avg reward -2.8333333333333335\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 79 \t Episode Reward: -6.0 <--\n","Step 237078\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0], maxlen=100)\n","Avg reward -2.8734177215189876\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 80 \t Episode Reward: -3.0 <--\n","Step 240079\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0], maxlen=100)\n","Avg reward -2.875\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 81 \t Episode Reward: -1.0 <--\n","Step 243080\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0], maxlen=100)\n","Avg reward -2.8518518518518516\n","---------------------------------------------------\n","our team scored !!!\n","-->Episode: 82 \t Episode Reward: 1.0 <--\n","Step 246081\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0], maxlen=100)\n","Avg reward -2.8048780487804876\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 83 \t Episode Reward: -4.0 <--\n","Step 249082\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0], maxlen=100)\n","Avg reward -2.819277108433735\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 84 \t Episode Reward: -1.0 <--\n","Step 252083\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0], maxlen=100)\n","Avg reward -2.7976190476190474\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 85 \t Episode Reward: -1.0 <--\n","Step 255084\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0], maxlen=100)\n","Avg reward -2.776470588235294\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 86 \t Episode Reward: -3.0 <--\n","Step 258085\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0], maxlen=100)\n","Avg reward -2.7790697674418605\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 87 \t Episode Reward: -1.0 <--\n","Step 261086\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0], maxlen=100)\n","Avg reward -2.7586206896551726\n","---------------------------------------------------\n","-->Episode: 88 \t Episode Reward: 0.0 <--\n","Step 264087\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0], maxlen=100)\n","Avg reward -2.727272727272727\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 89 \t Episode Reward: -1.0 <--\n","Step 267088\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0], maxlen=100)\n","Avg reward -2.707865168539326\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 90 \t Episode Reward: -1.0 <--\n","Step 270089\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0, -1.0], maxlen=100)\n","Avg reward -2.688888888888889\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 91 \t Episode Reward: -1.0 <--\n","Step 273090\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0, -1.0, -1.0], maxlen=100)\n","Avg reward -2.67032967032967\n","---------------------------------------------------\n","-->Episode: 92 \t Episode Reward: 0.0 <--\n","Step 276091\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0], maxlen=100)\n","Avg reward -2.641304347826087\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 93 \t Episode Reward: -2.0 <--\n","Step 279092\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -2.0], maxlen=100)\n","Avg reward -2.6344086021505375\n","---------------------------------------------------\n","-->Episode: 94 \t Episode Reward: 0.0 <--\n","Step 282093\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -2.0, 0.0], maxlen=100)\n","Avg reward -2.606382978723404\n","---------------------------------------------------\n","-->Episode: 95 \t Episode Reward: 0.0 <--\n","Step 285094\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -2.0, 0.0, 0.0], maxlen=100)\n","Avg reward -2.5789473684210527\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 96 \t Episode Reward: -2.0 <--\n","Step 288095\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -2.0, 0.0, 0.0, -2.0], maxlen=100)\n","Avg reward -2.5729166666666665\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 97 \t Episode Reward: -4.0 <--\n","Step 291096\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -2.0, 0.0, 0.0, -2.0, -4.0], maxlen=100)\n","Avg reward -2.5876288659793816\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 98 \t Episode Reward: -4.0 <--\n","Step 294097\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -2.0, 0.0, 0.0, -2.0, -4.0, -4.0], maxlen=100)\n","Avg reward -2.6020408163265305\n","---------------------------------------------------\n","-->Episode: 99 \t Episode Reward: 0.0 <--\n","Step 297098\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -2.0, 0.0, 0.0, -2.0, -4.0, -4.0, 0.0], maxlen=100)\n","Avg reward -2.5757575757575757\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 100 \t Episode Reward: -2.0 <--\n","Step 300099\n","lista apo rewards mexri tora deque([-1.0, -2.0, -2.0, -3.0, -4.0, -3.0, -2.0, -3.0, -1.0, -4.0, -8.0, 0.0, -3.0, -3.0, -5.0, -1.0, -4.0, -4.0, -1.0, -3.0, -5.0, -3.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -1.0, -3.0, -2.0, -1.0, 0.0, -5.0, -4.0, 0.0, -2.0, -3.0, -3.0, -5.0, -4.0, -2.0, -6.0, -3.0, -2.0, -3.0, -3.0, -3.0, -5.0, -5.0, -5.0, -2.0, -3.0, -3.0, -3.0, -1.0, -4.0, -2.0, -3.0, -2.0, -3.0, -3.0, -2.0, -4.0, -3.0, -2.0, -3.0, -3.0, -2.0, 0.0, 0.0, -3.0, -2.0, -2.0, -4.0, -3.0, -2.0, -1.0, -6.0, -3.0, -1.0, 1.0, -4.0, -1.0, -1.0, -3.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, -2.0, 0.0, 0.0, -2.0, -4.0, -4.0, 0.0, -2.0], maxlen=100)\n","Avg reward -2.57\n","---------------------------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eZQkV33n+70RkXstWYt6767ShqRGu1pCCAmlgIcB2+Ad+2CDZ+zRMMc2vHnjDWM/22OfN4zt8e5jngx4sM1DGIwBYxYhpJKQAO1La2v1VlW9qruyuraM3CLivj8ibsSNyIjIyCUysyrv55w+1ZUVGXFju7/72wmlFAKBQCAYPqR+D0AgEAgE/UEIAIFAIBhShAAQCASCIUUIAIFAIBhShAAQCASCIUXp9wBaYXp6ms7OzkbevlQqIZfLxTegAWUYz3sYzxkYzvMexnMGOjvvp556aolSepH3800lAGZnZ/Hkk09G3n5ubg6FQiG+AQ0ow3jew3jOwHCe9zCeM9DZeRNCFvw+FyYggUAgGFKEABAIBIIhRQgAgUAgGFKEABAIBIIhRQgAgUAgGFKEABAIBIIhRQgAgUAgGFKEABAIBJueE8sqHjx0rt/D2HQIASAQCDY9n3zkOD702Wf6PYxNhxAAAoFg07NcqqFS1/s9jE2HEAACgWDTs1Kuo65TGIbocNgKQgAIBIJNz6paAwDUdKPPI9lcCAEgEAg2PSvlOgCgqgkB0ApCAAgEgk3PimoKgJoQAC0hBIBAINjUGAbFWsUSAMIE1BJCAAgEgk3NekUDtXy/QgNoDSEABALBpmalXLP/LwRAawgBIBAINjXM/g8IAdAqQgAIBIJNDYsAAoCqJpLBWkEIAIFAsKlZUYUJqF2EABAIBJuaVV4DEFFALSEEgEAg2NQIH0D7CAEgEAg2NUIAtI8QAAKBYFOzUq6BEPP/QgC0hhAAAoFgU7Oq1jGVSwIQtYBaRQgAgUCwqVkp13HRaBoAUBNhoC0hBIBAINjUrKg1bBtNARC1gFqlrwKAEPIOQsghQsgRQshv9nMsAoFgc7Ja1hwBIExALdE3AUAIkQH8DYB3AtgP4GcIIfv7NR6BQLD5oJRitVzDtBAAbaH08di3ADhCKT0GAISQewG8B8BLfRxTrDwxvwyJENw0M9HvofQF3aD4zGML+KkDe5FOyIHb/fvzZ3DtnnHsncz2cHSCqJxZLeMfvrcA3Wq/OJVL4u43XwLCQnF6iFrTUdcpJrIJpBSp40QwSik++/gJvOuaHchnk5G+8+iRJYymFVy7J+/6/NkTK/jawTP271fvHse7r9sVaZ+Vuo5/fvIE3veGGchSfNe1nwJgN4AT3O8nAbzBuxEh5G4AdwPA9u3bMTc3F/kAGxsbLW0fN//PY2XIBPiNWzKxHmfQzpvxclHH/3yiguUTR3D9Nv9Hj1KKD92n4u2zCbz3imgvIDC45xw3/Tjvrx6t4QuH60jKgGEAGgUmSgvYlu2NQYE/52LZnPDPLB6DBAPH5hcxN/da2/s+vWHgtx4p4+DLh/ADs4lI3/n1h1XszEn4rzelXZ//xdMVPHtOR0IGdANIK8DYhVcj7fPZcxr+/OkqqmeP4vIJc7EUx73upwCIBKX0HgD3AMCBAwdooVCI/N25uTm0sn3c/NkLj4ACKBRuj/U4g3bejDOPLwJPHMTlV74ehWt3+m5T1XTo3/wGRqe2o1C4LvK+B/Wc46Yf5/1o6SWk5xfwyh+8E9944Sw++E9P4errD2D/rrGeHJ8/5xdPrwIPPYI3XH8N/m3+IC7asQOFwjVt7/v+l14DHnkSiYmdKBSubrp9TTOw9M2vY/f0KAqFN7n+9jevfBdvuITg3rvfiD/91qv4qwcO44433xlpRb/23Gng6Wdw8RVXo7B/O4B47nU/ncCnAOzlft9jfbZl0QyKUlXr9zD6xnyxBACo6cGhepW6uaLjszsFg8WKWkc+Y2pnuZS5OlVr/XmuV63nJJ9NIClLHfsA2DM6X1QjbX9qpQyDOuPg4a9TPpMApcB6JdpzXamb7whf6TQO+ikAngBwOSHkYkJIEsBPA/hKH8cTO5pOodaGN0550XqpqvXgl7RqPfirMT/4gvZZLdeRz5rmkWzSNCKU+vRcswkyn00gqXQuABaXzWd00RIEzViwtvN7XvnrxH5GXdj06j3omwmIUqoRQn4ZwDcByAA+RSl9sV/j6QWaYQy5BmC+XGGx2kwDEAJgcFkp1zGeMSc0WwPo03PNJtR8JtkVAcCe0ZMXyqjrBhJy+Bp5wdp+pVwHpdR2hFNKzevkEQBRn2v7PeBKXcdBX30AlNKvAfhaP8fQSzTD1AD4B2VYoJTaq6Wwl7RiZXIKE9DgsqrWMTttRmjl+q4BmBNkPptASpE7TgRbKJagSASaQXF6pYyZqVzo9sxkpBsUG1UNo2lzoq/UDdQ0wzYBjVs/o5p0hsEENHRoOoVm0KHMVjy/UbXNX2H1WpwHP96Vj6B9Vso1e2LLJvvvA0gpEtIJGUlF6qgjWF03cPJCGTdaYdpR/AAL3Db8ooUXTPzPlYgr+l4thIQA6CGaYU58anX4/AD8ixKqAViqb6Vu2MJAMFisqI5tO5eyNIA+PdP8WDp1Ap+6UIZuUNz5uosAOPb9MOaLJaQUcxrlzTuOaSrh+tmqCUhoAFsIljhT6tNqqZ/MLzkvUxQNABB+gEGkUtdR1Qzbtp1SJEikfxoAr4106gNg5pybZyeRSciYXwrXAHSD4sSyiqt3j5tjURsFALtOzGcS2QlsaQBx+wCEAOghmiUAhjESaHFZhUSAdCL8JeUFgPADDB680xUACCHIJpW+aQCrnKPVNAG1LwBYBNDsdBYzU1ksLodrAGdWy6jrFNdZGcC82XKVmYCs66TIEkZSSuRnWmgAWxBNtzSAIYwEmi+q2DORRS6phOYB8C9wVHupoHewSY6taAHTD9A3DUCt2+aVlCJ15F+bX1KRTcq4aCSFmalsUx8AM2tetzdYA2DmKcC8ZlF9W7YvTPgAtg62D2AINYCFYgkzU9mmarpLAxAmoIHDb2LLpZS+RQGtciGpnZqAFool7JvMghCC2akcFouqbbb1g5mMmAbg8gFY/+cFZT6b8E0Y84NpAGuVeugYOkUIgB4yrBoApRTHl0qYnco1FwDc36K+LILeYdu2vRpAH/MA8pw/ohMT0HzRfEYBYGYqh5pu4OxaJXD7haKKpCJh32QWmYTs0lhX1DoSMrGjpABTAERd1DAfQCvZw+0gBECPoJQOrQ9gRa1jvaKZGoAcrqZXXRqAMAENGmtlHw0gqfQlsKFS11Gu63bVzk6igEyHbhkzVn7D7JT5c2Ep2A8wv1TCzGQWkkTMyZ1bsJiaSdKV75PPJKOHgfYoGEIIgB7Bq3HDFgW0YDnXZiwNIKwUBHvwJSKcwIOIE9/uVGrNpuS+LGrWPGaWTkxAZ9cqqOmGowFMmz/D/AALRdVOFDPt+7wAqLmEJGBGBLUSBspqxsX5HggB0CM0TgAMWx4Ai6eeZT6AJqUgZIlgIpsUPoABZEWtQ5EIcpxpI5dU+mLWXPFoI82erTDYSn/GWvnvHEsjqUhYCIgEopRiYblkawpe+z7vnGbkM6aWQGlzm36lrmN6xGxyE+d7IARAj9CGWAOYX1JBCLB30jQBNcsDSCuSuVoSGsDAsWIVOONNG2YUUO8XNd6Q1JQiQzdoW05TttJnK3pJItg7kcFCQC7AufUqKnXD1hTymaTLZMn7Jhj5bMKsCBzhWlU0HTvG09a+4jOFCgHQI3Sd0wCGzAewUCxh51ga6YSMVEJuWgsonZCRz0RXlwW9Y1WtuxzAgBUF1A8NQHWXW0haGbntmIEWiiUkFQk7x5ymLrNTOTvSxwtLbJyxutaNZ/x9ADxMUEWZ0Ct1A9utsQgfwBagbjgP5bBFAc0XS/bKqpmjrlI3TAGQTQon8ACyUq41tErMJmWU+1C2wxtqmbQqd7ZTD2jeCgGVuGYtM1M5LBRVX5MNywFgPoO8x76/ovr7AMy/NZ/QK3Ud28dSkbdvFyEAegSvlg6fBqDa1SObJetU6jpSCcm2lwoGCz/bdi6loK7TnjdkX1UbfQBAuxqAatvzGbPTWZTrOs6vVxu2n7eqhu7Km6v08WwCVc2sX1XTDJRqesN1Gm+hHlC1bmAklWgpe7gdhADoEXVu0utX1mQ/WK/UUSzVHA2gScXGSt1AWpGFD2BAWVGd0guMflUEXSnXIEsEI1ZBOiYAWs0FMEuVqw2ln9nvfpFAC0UVeyezUCytwzHv1O0J3s8HADQXALpVMTidkFrKHm6Hge8J3A3+7bnTeOH0Kj7yzqtiO8a/PHUSB2YnAuuHt6MBnF4p4zuHz+O9N+8L3KamGfj7R4/j5980i5QiB24XByeWVXz/WBE/eWBv4DaOqmyurpqZgKqajnRCQj6TxHpVi9SUYytwYlnF944V8VMh13IQWC07bQ4ZfE+AfNbvW61z34tnsWM8jWutLNvgsTgOaVaVk9cwz65WcM/Dx+ws/HwmgQ+99XJ74gaA8+tVlOt6owZg/f5XDxzGxdPu9/rx+WW8nuuBbJd7LtegWGak8WyQDyBcALAFkmkKjXchtPXfLADPn1zB3z86DyOmlGpNN/CrX3gOn3viROA2dc4JHNUH8K/PnMJv/MvB0O2fnF/G//j6K/j+seXoA+4Sn3viBH7tC8+HruiZANg36WgAzUpBsAcfcGK9tzr//OQJ/HqTa9lv6rqBjarW4ATOxtAV7Lf+9SA+8Z3joduseBzSKR8T0DdfPItPPXocX372NL749Cn85QNHcOi1ddd+Tq+a2b678hnX57vzGVy7ZxwvnFrFvz132vVP0w285cpt9rZ5rtqntxS0vQ0nJMJgZSDSitRS9nA7DIUGMDOVQ00z07q9N7kbrJbroDR8Ym9HAyhb25Vqml133cuGdcx+FE5jx14t17Ft1F/7YFEULL461VQAGBhJKU753HIdU1Y89FbmgnX/yjW955pcVIJMG93uCrZeqWNpo9a0HwRfCRTw9wGwZ/Sx33ornj2xgp++5/sNK2onmsi9YldkCV/55dsjjZl38CZkYu3PfZ3SCRkpRWq6omfnnUrIGM8kcHZ1PXT7ThgKDYB56hcidPhpByahw14A5gMYSUVPm2cPQljiGBMm/QiZZDbfsAd6oVjCRaMpW4A1TwQzNYBWIia2Auw8+1VULQpBAiCT7K4GsBChdzTQ6JBOyuY4eB+AWtMgSwQpazUNNCZWBZ1XKzDhsVquNeQnuLdrHtzA3nvTB5DEajk+38pQCAC2+ozS4acd2A0Nc4IxDWA8k4icCczawoUJDPa3fkyUbLIKU1HnPdEVSUVCXaeB5jg+DwBw6qpvddgk1K+ialHwKwQHdF8DsAVAE2euNyTVTwMoVXVkkzIIIYE2+CCTTSu4TEA+lUCd7ZqHNzsmIMsHUK5Fyh5uh6EQALvyGSRkEqnHZzuwSSqsKQZzQo2mW9EAmpePZsKkHwJArTYXPoue6Iqkj6OOx8wDkOwXW2gAg8OqTx0ggPMBdCkKiJVfaCoAPD4A59lyrqFa02wBFWSDXw2ZsKOSTcpIyAQr5TpW1RoIMd91L+NRNADeCZxJoK7T2ELHh0IAyBLB3olsXzUAVgp6PJNApW5ESldnqmCYb8HWAPqwUrY1gAD/Q7mm4+xaxa0ByOGhepW6aQPnV1TDALt/m0EDaMgDSHa3LzArvxBmAtJ0A+sVzWW2Yc+WSwOo6baACrLBr6h1jKYUV2RQqxBCMJ5J2hrAeCbhSipjRMlwd3wAwWarbjEUAgBApA4/7WKv3kI1AHPCH7NeniirpSgaAHMU9yNm3vYBBDyci8vu+iqAf6QGT9XKBB7LxPvgDxqbQQPwawYDdF8DYIEDYRrAWsU8Fi+MUonGxYVadTQAoLFkA2AKX29uQzuMZxTbBxBkToriA2DjTydku5xEXEEeQyQAclgslmKxpbFJKiwdXuN8AEC0SCAWEhhNA+iHAAg3P3kjgADYES5+qzs+AUaWCMbSSuxNsQcBtpoFBjtJcKVct0wbHgGQMO9p1zQAa6EWltDlF7kTqAE0NGXxmIB86hu1Qz7LaQDZRgcwEK0tJOuJwXwAbIxxMDQCYHYqi1JNx9JG9ycUNkmFTdSaNeGNWS9PlFwApgqGCRbHB9D7idI+dsADzUxuM5M+PgCfl5tPgAGsF2oINAC2mgUGu0zIqlrDWDoB2WPaUGQJKUXqivBiZkMgXAOwHa3cyj3lkwmsekKo85aZxruvTiKAnH2bq/tVtRaiASRRqRuhIa62E1iYgLoHK9sahx+A3Zywl7cdDYA9CGErq1ITM0ycNItAmi+qmMgmmsZqM/gEGKCxwNZWhRfeg1woMGyizLUQ3hwGMxuOppRQDWDVxx/h92ypVbcG4NeUZUWt+YZstgrbd9h1ilIPyAkDlSNnD7fL0AiA2ZC6Hp3i2G+1QBMTcwKPZZjDLLoGELay4s0wcYWK+UEpbZqD4I0AAsIrNvIPPuBvr92K8Ku7QdYAwmzbZl/gzsfOFmiXbx9BLSQr2q8zmV+EmVrTXT4AvyKD3oSydmEtH5v5AIDwCd0lACJmD7fL0AiA3fkMJBKPBsAmQEqdVawXFgbakgZg+wBCNABLkGhGfKFiflQ1J5IpSACYTbbd9VXCNYBGE9AwaAC8fXeQmwWF2ba71ReY2f9ft300NArIVwPw9QFotpMaaPQBUEpDJ+xWyGcTKNV0rFWCr1OUngAVzTEBRc0ebpehEQBJRcLuiUws2cD8JBX0EtgaAPMBtBQF1FwDAHrrCHYd1+fhrGo6Tq+Usc+rAUQxAVnRHOMZpS++jV7DT0iD3C50rRzsLO1WX+D5YgkT2QSmR1KoaUagVsue9TFuPIpsBg+wZ4tpqS4NwGODL9V0aAbtjg/A2gelwUllUWz6Fc4JzL4jTEBdYHYqF48PQK3ZPVKDXmA7E9h6AKK86PxDGkSpptnH7uVkyTSPXFL2Pe7JC2UYFIEaQNVndcc0nhTTADKmBhBXEb9Bga3uckl5sDWAEOdmt/oCLxRV7JvKIalIMKi7lap7LHWMppUGh3RSdkqNMC2V1wC8Nng7mqgbPgDu2jT1AYSagAwkZcnOIxiPsTveUAmAOHIBDINitVy3i8wFvcCsI1grGkCVaQAhL5Za1e1j9zIXgK32duUzWKtoDYltdgSQRwMIywOocinwgPkSGRRYH2DHaDdgq8Ed4+mB1QDYcx40sXWrLzAzGzZr7hI0lqQi2WGUbDxuDcArABqjidqF90cEXacoNn3WFMn+ToTyEe0yVAJgdipneum7uFJer2owqFNKNshcoxtuJ3Czl4XFxAPNawGxY/fSBMTGxI7tLds8v+TuA8AIEwBOCjwzAcUbAz0osNXsWCYxsBoAe86DTEC5lNKxAKhpBk6vlDEzlWuaMBgUucMXG2QaiSsPwBNVYxeC64YPgNuHtx8wYyRlai1hK/qqVQ/L3pcwAXWHsA4/7cImJ1sDCFjBsX4A2YQCRSJN1WVXKFvAi6UbFJW64QiAXmoAVUcDABqFz+KyitGUgsmc+0Xwq9jIqPo4gc19b20/AFvN5pKdT6Jx4bRf9J/YTA2gM+F18oJqmw2b1YwKCrVMypL9bNkaQKpRA2CLwJUm59UK/HiCNACzKF34hM7qYdn7Eiag7jAbQ1VQNjnttnqDBmsA5kOpyCSSuswnigQJC3YsduxeTpQl77E9WtV8sYSZ6azdrYkRzQnsmIDMfW91DcBczWaT8sDmAdhhlyEaQKeZwCxAY2Yq5xvRwxOUvZtKOP0m2DPqygPwlBjpRilo7769/2/YrkmTl0pdt82gbGxCA+gCeyeZAOieBrDSogYgS8R6WcJf9AoXAx0kLNjnE7lkrKFi/sd2m4C8D/RCUXVlADMcARCWB8D6rA5HPSC2mu2GGSUuguoAMTIJGeW6HqnIYRCsdAivAQQlg4VpAEwAMC3VTwNg7woTbN0oBTGaToCtd0IFQCa8zSPricHIZ5Mo13XU9O4HQ/RFABBC/pgQ8goh5HlCyL8SQoIbf3aRdELGzvG0/aB1AzY5RfUBJGTJ1ACadDtiq+F8NhEoLJxIHCXWVYL/sd0mIP6B1nQDJ5ZVVw0gRphq7w1/G7df1i1uArJWs90wo8TFSpOVcs6KtAkrW9KMhaKKEcts6JR1aNyfQWmgDyDF+wB8NABmg2cT/6pat+PtO8WsX5XASEoJ7WOdb1IPyGsCsnOH6ltEAAD4FoCrKaXXAngVwEd6deCZqWxXNQA2Oe0aZ1FA/i8AqwUkEcth1kwDsF6kyVwSak33jYdmq8VsUo41UsAPWwMYZ/4H59inVyrQDGpnX/OEO4HdJiBbXd/qJiBrNWuagAZTA2DPeZBzM2tF2nRSznq+WMLMlGk2DDUVaoBB/YWRGQXkzp/JclFAZtlmZ7Hk7SnQKflsoun+WNG4ICqaVwOwIgdjeA36IgAopfdRStmT8n0Ae3p17NmpHF45s4Zf+/xz+LXPP4c//darkUso6AbFXz9wGMWNqv0Zu5Hbx1MgJPgF0AwKRSIgxPQBNCv7ywTAVC4JjYsI4rE1gJTSUqTA555YxCtn1yJtGwSbqLaPm/16eTONXxVQhnkNwjOBmZBIKTKySbltE9Dh19Zx7+OLodusVer48/tftVt2dov7X3oNjx5ZarqdYVDOB6A0mFFW1Br+6tuHG0wrNc3An9//atNV4WceW8Dh18J7ys4dOocHD50L3SaoGxiDaQDsuS7XdPzeV16037Pf/tJBnF+v+n6XsVBU7UWDXTXW5zkp1d11tXjcUUAsDNS9ujdX4I4JqBs5APy+m/kTmpuADFdfaDa+jRg0gEFoCv8fAXwu6I+EkLsB3A0A27dvx9zcXOQdb2xsNGy/TdOQlgx8+8VTqOkUG3Vgb/0kLso2l4Xzqzr+5HsVnD0xj7fNmDf5hcNVpGXge498BykJOHR0HnNzZxq+e3yhBgkUc3NzKK9XsFKloefyctF8eI2yOVF/64GHMZJ0O1SfP28KgFdeeA5aqY5zqoG5uTnf82ZoBsVHvqXiLXsV/Oz+9putHzpaRVIyzzujAC8ePo455TQA4IFF8+E+/epzmFtsvK4KAQ4fX2i4Tq8erUGRgIcffsj+LCcbOHhkEXNz4ROU3zl/5uUqHljUsEM9Fvi9R0/V8XcHa0itnsBVU91rxv7fHy0jKQO/fWsmdDu1TmFQYOn0Itjrfd8Dc8go5r1+5FQdnzhYQ2Z9EZflnfG9XNTx509U8HOXU2QD7nVVp/jot1T8wIyCn7kq+F7/7nfNpL0/eFPwWJ95pYpcAvjuIw/7/v3Ya+az+PB3v4+FMRnPn9fwv5+qYjxFQACsVClSG2dxxx7/yVE3KBaLKvaP1jA3N4dXL5jP/xNPP4vyovu+LK2pAAhOHjuEuY2jrr+tr1awZr1bB4+bz+FTj3/Pvp4AQOplzJ8qY25uDvOnywDQ0rwSxuXZGnQjfH8r52pYr2q4/4EHofg0jbmwqmKUlux9LK7pmEwTbKjlro2TEZsAIITcD2CHz58+Sin9srXNRwFoAD4TtB9K6T0A7gGAAwcO0EKhEHkMc3Nz8G5fAPB/Wf//3tEifubvvo9dr7sWb7psuun+vvr8aeB7zyA5uRuFwn7zs/PPYWqliEKhgNFH78fk9m0oFK5t+O7D6y8hefoECoUC/uXMM1g/tdowNh566BzwxBN43cxuPPXaIq6/+Q3YM+FeUZeePwM89TTueOMtOKQdw5nDSygUCr7nzTi+VIJx3xwmLtqBQuG6puccxH0XDmL0/FkUCgVMP/4ARicnUShcDwB45KsvIZ1YwI/8wF0NUUAAkJ77Jrbv3I1C4fWuz+fWXkT2zEnX2K88+hhWy3UUCreHjsfvnL/y2rPQF07h9jveHNjt6en7DgE4gsl9l6Nw877mJx4R6YkHsVLVQ+8xAJxYVoFvP4ibrrkSVc3A5w69gJtueSO2jZnRVUe+cww4+DKmZ65E4Ybd9vfOPL4IPHEQa0Yy8BiHzq4D33oYI1PB95pSiuKD94FSijvvvNP3fgHAJ48+hsu2B98H5fAS/uqZx3DVNTfglosnMf/oceCpl/DtX3srkoqEa3/vPuycuRSFOy4JvA76fQ/izhuvQuHmvZg4sQI89iiuev3VKFy13bXti1/4NoAKbr/lRtw8O+n6270nnkJ1qYRC4c14pv4qcOgw3v6Wgitj+NPHH8f5jSoKhTvwsWcfxr7JLAqFA77japUo09N84ji+dOQl3HDLbZgaaRTM0ve+jX27p1337P3v9n/GOyU2ExCl9G2U0qt9/rHJ/+cB/BCA99FelrHkYCaKqE5h5jvgw0hX1LpdjyQXYsPVDQOKTJztmjj7qpwJCPCPBOKdXFErZ7Jz7TTaRK06RbbGMwmPCciMAAqaTHhHHY83AQYw79HxpfYa+bAxVULKCrOckG5niJu9J6rYaGIT500rXjMK4IQpep9R9vtrati5lax9BPuGiqUaNqpa014ZrERDEFl77Jp1bBW5pIypXBIjSQUSCfflsLHus97JMB8AMwH5haTyJiC1piGTkBvKRfA2+BW1O70AWsHJb/G/HhXN7QSOk35FAb0DwK8DeDelNJ4+jRHYMZZGUpEiO4Xnl8yHlH8ZV8tOfZRsSCJP3fIB2Ns1cfaxKKAJSwD4RQKpriggM1QsrNEEACxY59BpxmmJK7LFyuDax7CceUHwoXo8lbrhSoEHTJ/NekVryxHMxhR2TZgw73aNKHZvmu2XL2ucTTaWCmfn7X1GWd/cc2qwYGTHDrt2/PiCxlrTDJy8oDZkdfPkbCewbu9rZspcBEgSadoJiwlg5gMICwPdaOYDsPMAdFuo8vA2+JVyrStJYK0w3iS/hfXF7gX9igL6awCjAL5FCHmWEPLxfgxCkghmJrP2xN4M9hKeWC7bTjl+BZFLBYfx6TqFIkn2dmG9AwC3ExgI0gCsKKCUbL8M3pIMXtiL1mnNmTLXao9PbDEMioVlFbPTwavFVEIOdAKnFa8GwLK3W5+gbQ0gRADYGsBS99YhhkHtMN9miws+vt6eROqYDSQAACAASURBVH0qvLanAaiuffhuw513kBZ0asX0EXjrOvGwZ4EtLBaKKmanHYHRLPJlYamEdELCtlHTJBKWCMY0gLEAAcBCR9Wq5ooAcsaSwHpVw0ZVQ6VudDUKKApsweinmVFKrTyALawBUEovo5TupZReb/37YD/GAZgPdWQNoFiyqw2eWTWdR3xCSjapBEb31A3DVkWzSQUGDe95yoeBAgEaQE2DIhEk5eit49gqr3MNwGm1l+dWVK+tV1DTjDY1gEYTkJO93foEzcYU1KNhRa1htVxHUpaw0MV+0RVNB9tVM8HF16LxmlHYGAGzuQ6DUorFZRVJWUKpHlwriX2nmQYgETOGPUgD4BO0gmDPglo1CwOeuOBuBtSsoiUzG7IKmHaDd7/otzpFJiH7xu7zpSC8/YAZbAJm16dvJiCf+6IZZlCAdyEUF0OVCezH7FQWC8vNX361puHcehW3XGw6nRaKKiilVhKPeUNzKTkwDFQ3KBLMB8Be9BD7MLNbT4ZpAFa7O7O+SLTWcQtWy73OfQDOy5W3NABKKVcELni1yK/SeLwJMICZvU1I6xoApdSecII0ACZUbrl4EqWajmKpO3kUvB9osYngYmMcyyQazCiAo9EVSzWsVcz/n9+oQq3pzrO4HD5xr5WDu8UtLKvYPZHB7nxwrwxmNoymAZh9IOo6dQmMZu09F5fdZsOUHBYGGjxppzgTkLcfsDOWpH1MoDuloFvB0QAar4e3KVLcDL0AmJnOoVI3cK5JjDLrVXrn6y4CYL5cZnq24dIAgiZWTacuDQAIn4RtE9BIsADgH3BvkSs/dIOaUSfovPes2YfA8QHoBsVGVePKQIdoAAFOYG8CDGBlb4+lm06kjePT7VryfsIGcCZIdk+75QfgzYDNBNeKWrNXs2wS5b+/Uq7bny/aQQjmzze/bto6RuO1YQ15skkZNd0IzNCdt2LvzQRJ/7EuLJsO3emR4IkypZjNWNSa5qrpwwgrgGYY1DIZOduHOYE36jTQbMMCDCil9gLJC7PBL/RJAxgLSXD0NkWKGyEArPpAzfwAbGV7y8WTSCoSFouqY7/lo4CCOoIZhp0enks2qvpeWFOIEaZa+2zLq7jeIld+sJXZSBdqzqg13YkC4pxa80UVCZlg53hwTHmoE9hH9d03lW1ZA+AFYZAJiE0At19uTaRd8gMwDWAkpUTyATg+JB8fgFrHNbvHzfFZ14A9q3dcbgkun2eXNeRh3w2afBeKJeybzIb2ymARQEFRXQCcBMeq7psIaPoA/Bcnr61XUNUM7Jt0tm8WBRQ0aScVCZSyFqmaqxeAPRbrXWHn22sfgCwRjKaVUA0gJTSA3sBMFc1eVLY6mp3OYd+kOSF5C2RlU8HRPS4NIMWiPcI1gFRC4iJDfDSAaqMGEJZhyM7xqp2jTZ3QzShVeQ3AUWkXiiXsncw2hN7x8JEaPNUA59dsC34aBj/hBZmA5osl7BxP49KLRrraL5oJ66t2juLMaiXUCb3CtVn0OlJ1g2KtUse1e8xJfIHTAGSJ4LJtI8iniO/Ezc7lur1mmS0/AcAamM9O5UJ7Zfj1dvbDLGdtaoEpRcL20bT9t/FMwrdxEABfs6EsEcgS8dXeSnUaaLbhBUepqru6gTGYCYhdo15rAOyYfte6qgkTUE/ZlU9DkUjTFeZ8UcVkLonxTML0GxRVrpKg5QOw1G2/yU0zqJ2MlPNR9b2wmHhZIkgnpKYagLfIlf85mOe4f+dYaAP7Zmi6gapm2MKJd2oxk0IYpg8gmhMYME0JvA08CvzqKkwDmLEqT+6eyHQtF4AFAuzfOQbAMR/6jpPTAGwziiXs1yt1UArsHM/gotGUPWHNF0vYM5FBQpawPevvvGXCggkPv+fCMdVkA3tlMLNhmP2fkU2ZJU7mresqcYsAdo5+UWpBZsMgTTHMB8Cih6qa0VQDcExAvfUBmGNI+mrrtglIESagnqDIEvZONi8Qx8e2z0zlMF8scU0yHB8AYIZIetEMw84DyLCVXqgG4DhEc0nF11yk1pwwtyiNJtjK7GLL1tpuJBALcWTObL7N3WKTHAAgOBEsKAGGrT5b8QNE0QAWiiVbWHWzXzQLBNi/yxQAYeZFvhaNUyfK/D6vYc5yJpqFomqbS7ZlpQANwKysecn0CAB/zXCe02qDemX4OXSDyCUVlGs6FouNAiMsSo2ZDVllWUYq4f+clOo0sIVjkqshVKr5awDMBn96tQxFIg21gnpBUPVe4QTuAzNWJFAYfKGq2aksKnUDr762AQDg8wAA/4lV051EMCfeO8wH4MTEZ1Oyr2lJ9Ti5mjWaYCvekXT0xvR+sO9lPSago+dKKNX0aBqAz6rcLw8AaC8XgF/xVnzMCBtVDUsbNXvf5jPQbQ3AXH2HaQDeTNQclyTIl2CesQQUpdQyyZjj3p4lWNqoNjj1WWXNiVzwxMsE6r7JrB1t1ZBw5uPQDSKTlLFR0bCw3GgycqLUGjWRxWV/s6GfBlCp66gbwZE7rJCgWtNQ0wxfDYDZ4KnV4jLMtxEXQWGx3qZIcSMEAKzV35IaaBOvajpOr5ZdGgAAPHdyBQA4G27wxG6agJgPoDHl3wtvDgnSAEoeFXc8kwhNBFuwVmZRnNBhsO8xgcdWVOx6tKMBOAkwfgKg9VwAtwbQKGxsn46179mpHFbU7vSLZvd/Zz6NfDYRKLgopS4fAMDMKEwDcEyMs1NZvLZWxZnVCtYrmn1NtuUk63waJ+7ZqVxoePB8UcXO8TTSVhTSzrHGXhlsYcQndQWRS8o4XiyhUjcaBMZ4mAaw5G829PMVNWtMw3wA7Dh+UUD897vRDL4dgnwA3qZIcSMEAMwV0HpVw3JAHPiJ5TIoBScAzJ/PnVhBUpaQYRN1Kti0Y5aDdkw6QHjtdN4EFNRCUvU4uZqG2lkrs2xIZFEUvBqAOYFIeO4EEwBNNACflV1dtxJgfB78XErB9EiqJRPNarkOtqD0MwF5V7b7utgtzu5Fm1RCEw0rddNfNO7VAKzvr3o0AAD4zuHzAByH6bYMscbtXBtNN0s3zExlkU5ISCpSgA+g5Iq82efTK2OhqCLpcegGkU0pdsln7yLADhTwPJ+U0oZxMJKK1JAI1qw1pS0ArMnVLw/A/H4ydD9xk88ksVquw/A4xSuD6AQmhHyYEDJGTD5JCHmaEPL2uAfXK9jqJjgMzp0IszufgSIRFEs1jGcdFdKO2PE1AXE+gEQEDYCLifdrIUkpbdAA8tngpjDn1quo1A3s4zWANk1AtgaQ5IVPEsVSDbJEsDsfXgLZb2XX7MGfDQlT9GNFrWHaqrRY9REA3uJjLAa9G93i1KoGQkxhNjMZHMLqTGaOOYPvC8yHGbMJ9aFXLQEw7fgAzHE71+bMagV1ndrNVfhMbR6vw97PDzK/VMLMpNuhGwT/PHhX9E6ggPv5XNqoWWZDHwEgN5oKm/UlYALgQimaBtAPBzA7vkGBdc977TiBB0gAAPiPlNI1AG8HMAHg5wB8LLZR9Rg2sQenwrvD1BRZwp4Jc5LjVxB+mZwMnTMBSZLVGL6JBsBi4v00gKpmwKBwaQBhFUH5dP6MHYXUpg+AVSH16bW6O5+xX8Ig/BLBmsU/z7TopF0t1zGRNVsL+lUDXVhSMT2SsvMsuqkBlGo6sgkzQ3t2KotTF8q+0Sx+5gy+LzA/2bH+yt85vARCYJcGzyYIpnJJ17WZ9yxY/ByOpg+kihnOtDMzlcPSRg3rXLTVgo9DNwi2ADLzQNwaw1ja/Ftj72hrrD61o/xMhfY1CcoEtqKALjANwMcHADgCpF8aQFDtrkE1ATHx/y4A/0gpfZH7bNOzZyJjxYH7v/yLxRJG0womuIeOf7kYfrVcGHXdsE1AQHjdIMBctaZCooB4MwMjn01gPSDW2rF55yI5ocPw67TEHuhm9n/A7PakG9RukwnAXukFhb8xG3jUMa+odYxnE0gnZH8TkMdR2c1+0WpNs4XjzFQOBgVOXmh8tryJhADcUUDlGkZTChRZwng2gQnr/u4cS7s0pRlPopx3weLXLnSx2Bh77627xJsNo8BMoHsnsg39FxRZwmhKaRBECz7jYKQUGTWPA3+Vq57qh60BWALALwrI/H6/fQD+vplBTQR7ihByH0wB8E1CyCiA7vbQ6yMpRcaufCZUA5j1ZEKyl4LvkepXzZHBawCA+bKUQ/MAjNAoIGYmyCbdPgAAUH12u2Bn6KYjOaHDCNMAmkUAAf6N4ZslwLAVYlhEDc9quY58JoF0Qgr0AXhXtt3qF12q6rZwZKYav/0yG3+DD6Dq+ADGfRYd3nF7E+W8lTXHswmslt0PhV/svaMJW6WmLbOh3+rcD6YBBC0CxrONQQoLxVKg2TDUCRxYCsK87hes7YI0AMcH0D8TENCYn8HyYwZNA/gFAL8J4Garfn8SwH+IbVR9YHYqF+oD8D7UfhqAE9/vpwFQV5hbMw2ALwkbqgGk3D4AwCmX6z4H1V6ZRXFCh8E0gGzC7QMAomkAfqV+m4W/tVoVlIVXmhpAo7npzGqlYWXbTsaxH3x+Rph50W81m+E0gFVPiKgdsTTd+CzyGccLy+7KmqYPwD3RzBcbwzvtaKtld4+EyBqA9fwHmYxY0UDvOILMhn6mwpVyHTIJtu17ncDNfQD9NQH5aQCEOO9I3IQehRByIyHkRgDXWx9dYv0+g8HoJ9w19gUUw6rrBk5eKPsIAPN3r/oO+CeC6QZFgjMB5ZLBvQMAdxhoNqmgUjdcph2+GxiDrRb9mkfPF0u2wzOKEzoMRwPgBECWmYBa0ABcAiDc9sls4FH9AKzRR1qRG8oJMC3Cu7LdN5WN1MWrGaWq04hkKpdELin7Li78VrNmTwndDhHlV6isI9e+yUbNBYBd6G+Bu9eA/8S7UCxheiRp+0DMY1vRVkvuonMzkxE1gFS4BuBtHMTGEbS9X7TYilpHLkECY/cbnMABUUC2D6BfJqCA2l0sF6ZXuQnNJvH/Zf1MA7gJwPMwbf/XAngSwBvjG1pvmZ3K4oJaN8s7cw/F6ZUyNIP6mAsaNYCEbIbc+U2smmFA5kxA2ZSCgydX8CuffQYAcGBmAh+4bdb+O58Vy1eJHPUkcbk0AOuh8moAZqidavdPjeKE/sYLZ/DvB8/av996ySTe94YZc/813e5DwBi3TUARNACfbk/NNIDxbAL5bAL3PnECB0+tAQDeefUOvOuanQ3bVuq63ejDNAG5JxGWmTsz2agBAMCHPvtMQ/hgQiL48NsujyTg1Jpmr+oJIZiZyuG+F882lJs+dHYNCZm4hHg2qUA3KKqagRW1hh07xrjxZV0/GWwC/Z0vv4CLRtM4vlSyK5wC5mSn1nRUNafT1LzVscvL7FQWDx46h1/57DM4/No6FIlgV755CCjgmFuCzIDj2QROW300GPNFFT98XeM9BPxLhqyWaxgJmbO9PoCgLF92f3pdCI4xZofFup8Jv5LocRIqACildwEAIeSLAG6ilB60fr8awO/FProeYqvqyyVcm83bn9uq8mTjS/eO1+/AbZ5m8kEre82gSHAmoLdccRFOLqt48dQqljaq+O6RJVsA1HVztc/7AADT7MMEgJ8GwB7qjZpbAJRqOjaqmisyo5kJ6m/njuLwuQ3sGEvb42MCgHUD41cpb7p0Gm/fvxLaCYyR8vEB2BpASPjbj9+4Bw++cg4vnlrFmdUKTl1QfQUAHz+f8nECs9LfOzyRKgdmJnD17rGG0g0GpZgvqti/awy/GNDUnKdU07F7wjmP91y/C5974gRePLXasO0PXbvLdR1zXISW1wdw26XTeNNlU7j5Yncj9Ct3jOHm2QmcW6vi3FoVs1M53HXlNvvv49ZzsVquY9uouf+Fooo3XjLVMJ4fvm4XPv3deXusP3bj7gaHbhDX78vjjsunceO+Cd+/e8NRWUOeIA0j5eMDWK9oyCghhQY9UUB+HcEA4Lq947j9smm7WmqvSSdkZBKyrwmoVzkAQHQzzhVs8gcASukLhJCrYhpTX+Crgl67xxEAi5bJ4WLPxJaQJXz8525q2E82qfgngukUMmcC+vk3XYyff9PFAIA//uYr+PhDx0ApBSGkoR4IW1nxvgXVjsVv1AC8kaBM7Z7gbM1h7SsB0478Yzfuxh/+yDX4+ENH8bGvv4L1Sh2j6YRZCdSzQr5ubx73vP9A4P54Un4mIK15+Nvv/NB+/M4P7QcA/NL/9zRePrPmu51jWkkinZAbUu7ta+c5h21jaXz1V+5o2J9hUFz20a9F7kvsbUX4n++8FP/5zksjfdepFGv2QebNQzvG0/jML97a8J1MUsbnP3hb4D75JKxto2nHB+IjrD9w26xLE22F3fkM/vEX3hA8Dq5xECHEiQAKWDT4OYFLVQ3pkFnL0QDqSMgkMCR522ga//SLwWPtBX6mOVPz750AiKprHCSEfIIQUrD+/R1Mc9CWwYkD9/ZeVZFJyLjIiqhoRtDEavYD8F+58A1VgMamEFmfuH3bEcvZ4Zla6fUB+MVOBwkqc3unTDDQ6IBVA1rtRaUdE5CXfEjZCybw8tkE0orUkAjGzjsT8VisqXlYRyvX/mt6oOmhGUygn1uvQjOC6963grcQG/MVRHHYdxPvc96s1aSfAFBrOtIhGgC/uAha/Q8Kfnk7ZkP43pmAoh7p5wG8CODD1r+XsMWigDJJGTvG0g3OOuakiuqUCTKtaJ4oIB42MXtbGKa4TGCguQbAilypmlsA8H1nGWFOaDbRM6G4b9IdHsj3A26HpE+7P+ecoz2SLLnJr34Tm+hMH0CjCUitachYpbajYmZZR9QAuDyAVmEC/fSKaSvvRpiitx6QN0+gV/CNgwDzeSLEbPvph18piFJNQypgIQW4o2f6UeWzFcw2mV4fwICZgAghMoCvW/6AP4t/SP3DLxJovqji0ouivyh+fYEppa5+AF7yXEjYnonGmPgwDcC7is1nE9ioux8qJ+OUKzmQ8u9IBLjLBAPOSpF97q1C2iphUUB+HcH8yGeS0AyKUk13RbIATr2ZICdwqeZE6UTFXK01LxRX0wzUddqxBsAEQDcSlbztQqO07YwDvnHQXpjP0w5PUhtPyooCYiYjwHz20iGvoyQRJGSCuk7bFsK9Ip9J4uj5DddnVc0YLA2AUqoDMAgh/fGW9BBvvRndoFiM0OCEx08DYOGbSsCKM8856YDGphC2BlBzawCZhNxQoyWfSaLk9QGUHZMIIxcSBeTVAHIpxdWQxFuDqFWcRDDnOrWaADPumdR4eCdwOiE3lIM2nditjb9ZU3OGHSLb5vVhgtXRADoXAF4Nc75Ywngm0fM6ON7sV1aePAi/hMFSTUMyRAMAHC1gc2gA7meq2mMNIKqo2YDpB/gkIeQv2b84B9YPZqZyOL/u1FY/u1ZBTW8sbRuGn2mFNSdXgnwAHtXY6wT21QACVrH5bAKlWoAPIOP2AQTVAmKtEvkHkReOZj/gTkxA/hpAKwkw+YBEGsAUeLJEMJJSfE1AparWsgbTrNmOvW87Qa9NDcC6rqdXK+ZxuzBJj7JucdzEGzW5q5t4s1/5hjx+pBS3qVA3qBkm2eTRY4Jj4H0AnFOcMVBhoBxftP5tafhIoP27xuxm2628LNlUo3NVa6YBZNwvhtch6pe56400YYxnEjhcb/QBpBOSa0LPpYIb2C/6rMxmpnJ45PASANYPuNtO4NYSYLxaEw+LniGEIK2YJiCXGaGmt+zDCGtqzlPuUANg1/WMFS/fDScwIW4n9nyxhBv2+odqxsk4ZwLyNuTxw2sqZAurMB8A/712hXCvyGeSqGkGKnXDriLAVwHuBZGeUkrpp+MeyCDAJr3F5ZIpAAIyRsPw0wB03ZyQ+TBQnrFMkAZgrWR8aveUAiJx8tlEQyLYqlpvcCZmk8EN7OeLKt521TbXZ7NTWXzhqQrKNd2KAmp/dZUKiAJqZeUTlEoPWI3WWZ9d62WqcuF1pZrW4DeIcjzW1DzMeWwXymtz8mGa1emVin3cbpDPmKvNmmbg1IUyfvT63V3Zbyvw9yxKmQmvCYhprOkml9apojvYGgCvEWWSZi2koK54cRG1H8DlhJAvEEJeIoQcY//iHlyvcZydqvWzhKQiYedYtExIwDGt8I0e6ob5AAeFgbKGKrYPwOMETsoSFIm4BIsaEImTzySxUYfr+GZZBPdEEtTA3i4THJD5vLBcsqKA2n9IffMAWrR9BhXTApjAM//O9snXlVeress+jLCm5jylDjUA5tRfLtUatLZOGLc6UJ28oMKg0Up2dBv+OY/SatJrKmQCIBUSBgpsHg3AbxHTaxNQ1CP9PYC/BaABuAvAPwD4p7gG1S9G0wlXbfWFJRV7JzKRmmEw2ENX5uzOzAkctnLk66R4m0LYzcK5FXtQLH4+mwAFsMEJixW13rCSZCtNb92ioAgR9vuhs+ugtLPVlW8UUIsJMOEaQM02EbGXiXcEl2paYJngIMKamvPYJTravD6yRGwh0M0yBcwE5Ey8vfcBAM5z7m3I44f3OWG+uWYaABMcA68B+AqAwXQCZyil3wZAKKULlNLfA/CD8Q2rf8xMZTG/5GgArcZK+3UFq1sqbCLABAS4m3b4FUYzG4XwPgD/VaxtZ+UeqtVyowAI6gscNEGwdP2XTq9Z4+lCGKinFEQr4W9erYmHz6BlQpR3BKu11jUAR+CE+wFsDaCD68OubTdLFTMntre7Xa9hz7m3IY8fXl+RbQKKqgEMeBSQE51lPlOUmjWgetULAIguAKqEEAnAYULILxNCfhTASIzj6husLR4roNbqi8JeXt6+HkUDGM84aeF+TSHMRiHNV7F+jSZYaWSeoK5g3m5S9vishiQvWeUXOtIAAqKAWl35+FWXBOAq6Mf2yecClKqtawCs70NTDaDG+iW3/xKza9vNZiXMiT1fVJFLypge6U8dfPacm4urcC3E6ysq2U7g8GPYUUCDngfgeVd73QsAiC4APgwgC+BDMKuC/iyAD8Q1qH4yM5XDmbUKTl4oo1zXG2qvN8NPA2gWBgpYMcEhD0IupbijgAJWsX62cd4kYu8voCtY2MpsZipn19/pZHWlyBIk4hYA1TZsn36tDuu6gfWqZq+ebROQJVQ13UBVM+LzAVQ78wGY32UaQHdNQGsVDceWzCqgvSo37IU954vLzRdXDVFAVeYEDh97apNoAN6S0FEKInabqE/pMqV0A2Y+wJYqAeFldjoLSoFHjpghjy1rAD5dwTSdhYGGmIAySayUVwD4x8Q3aAABq1ivXZEvjcxjRxZ5IoHCWgDOTmXx7IkV6/udra5Snjr9FU3HZK61ValffZ41LgkM4DUA81hqvb0VeljeAU83NADm3O9mrXq2r4MnV/DGSxurgPaKfCaJs2vLWC3XI2sAzFRoawBNHr3UJskDyCZlJGTCvaut1cPqBlGXXJ8ihBwlhNxLCPklQsg1sY6qj7AJ/6FD5wG0lgMA8BMrrwGYN7aZBsBP2ilF8pQJdnwAYavYcc+qYtUzIfL7A3w0gBCzF/95p6srb6GvdsLf/DIp7TaLdhQQcwK7V5GtTg5hTmeeUk1DUpGQ6KCjk60BdDFTl93/C2q9b/Z/Ng52j5qFV3trRqm2E3hrRAGZ+RnJhhpgA2cCopTeCeAqAH8FIA/g3wkhy3EOrF+wuv+PHlmCLBHs8ulVGgabWMu+GkCIDyCbQFUz7BW7dxWQTTlx+2GrWG+jCb40smucPrkFrExwUIQI/3mnqytvu792wt9MH4B7QrYLwbE8AI8TmK0iW50c7KbmPmGnPGq1/UqgDPYMdTMKiL//3t4WvcTV47jJOBqigOww0PBjbJYoIMBdEM4b/t0LIl0hQsjtAO6w/uUBfBXAd2IcV9/IZxMYSytYq2iYmcq2vJLLJhsnVscHEG4CAswJ2281nON6xfp1A2OkEzKSsjPx86WR3eNszC5ebFIm2KUBdLi6SspSYyZwq07gbKJhQl61BZ5HA2AmoDY1AMBqrh5BA+h04mFaZDdNQH7N5fsBL4iaRdg5UUDWvatpUCSCJkFAm0YDANwlRrxl4HtB1Cd1DsBTAP4HgK9RSpvnxG9SCCGYnc7h+ZOrbb0obFLmTSuatdIN0wDydkhY3dUOkpFJyvbk5dcNjGckQWy1csVjErHHaTurHUE1b5e+8D9v3hyW6XCV6+321I4AGM8mUKkbrhDPFU+jdaYBeCNJ2lml+zXw8KJWW6806sVxAnc3DJTRamBDN+GbsTeLcvImDJaqjZ3o/GACIJPYHBoAy/ruhxM4qqiZBvDfYfYA/gYh5H5CyB90enBCyH8jhFBCyHTzrXvHjKcRSivYGoBPGGioCYiLM/erCJhLKijVNFBKm65icwni+ABUfx+AHQbKaQALTerET+aSGLUEXCfVQAEfH4BmRO4FwOBryzC8jdadTGBnFQm058QOCjvl6YYGwK5td53ATCBK2D4aPbO927D7EmVx1VgKIlofCib0N4MG4OcDGLg8AErpCoBjAI4DOAPgUgBv7uTAhJC9AN4OYLGT/cQBm/jb0QBSihniyGsA9QhhoLzztuKTDJJNyTCouZJttorNJZyJ37siZiQVCUnZ3cB+YbkUujIjhGDGWj1G7aYVRIpr+G0YFDXNaN0JnPHPeQAcX4hjAnJWkUB7GsB4FA2gjV4DXrIx+ADGrBKaM1PZljLbuw17tqIsrvx8AFGiqzZLNVCABX94i0AOmAnIqvvzCoBHYJaE+A9dMAP9GYBfB/DlDvfTdTrRAAgh5mrdpQEwE1B4JjBgTtymD8C9LVsVfvCfnrJXDEGrWFMDMG/ParkORSK+E17W074ySuLbzFQOx86XOp5EeA3AyXtoszwDtypfLdcxllbspLuGMNCONIAIPoCqhslcZyYWJkC6KQCYE7uf9n/AOadIGoDsyQS2e1EH97Lmv7c5NIAESjUdv/jpJ3Fu3TQFDZwTGMBlL5XAgQAAGOxJREFUlFKj+WbRIIS8B8ApSulzzex5hJC7AdwNANu3b8fc3Fzk42xsbLS0PUOuGLhhm4zKyZcw99rLrX8fOo4unMDc3DkAwDOvmQ/ss888hQtH/W9u2Wrj+NQLr+D8soaRBHGNnazpuHhcwtHTRQDAlZMSzhx6BitHG69fChqOrpQwNzeHl45UkVUoHnroocZxGhqOLpzC3JyZ8/DKSRWX5qXQa3aZokHbRdq6rjyl9TJqOjA3N4fzqvlovXbiGObmTkTex8KaOak/8sQzuCJXwdzcHA4erSAnG67xSQQ4dPQ45uRTeG7enMCfefz7OJxsTYitnq/hglrHgw8+GGiHLq6qmCBqR9cntW7g1p0yXn32MRxtImhbecbv2EVwcXKl43vXCbpBcetOGVPlE5ibOx26rWHVyX/1yDHMkZM4fa4MQoCNDT30HEY2dLx5j4LHHv1O3xLeopJd1zE7JuHQSTPs/PVTEo4+/wRO+FgL2p3PwogsAAghfwtgO6X0akLItQDeTSn9w6AvEELuB7DD508fBfBbMM0/TaGU3gPgHgA4cOAALRQKEYdsTi6tbM/zo+9o62sAgLHHH8TkRRMoFK4HAKgHzwDPPI1bb7kFV+wY9f0OpRTKA1/H1M69SK6cw67pLAqFA65t3v/uaMf/50P3QS3quPPOO/H508/gosqa73WYfPohjE2OoFC4CTXNQPGbX8fPXHUxCoUrAvfduJf2+PTxx7G0UUOhcDsePbIEPPwY3n7bDbjt0ujuoJMXVPzudx/E3kuuwEjpKAqFAj727MPYvzeDQuFme7vMA9/A9l17UCjsxwsPHAZeeRVvf8udtqkgKoelY/jqsZdx8213BNawoY/cj4v3bUeh0FmqzM9F3K6VZ7zNV6HrvPUt0bdN3P817NyzD4XClfiTg9/B9tE0RkZKoedcAPCfOh1kjygA+MUfibZtJ/NZEFHfgL8D8BEAdQCglD4P4KfDvkApfRul9GrvP5i+hIsBPEcImQewB8DThBA/YbEpMfvQOiYgVgwurBYQIcSOMum0KUQuAbvRxKpaD0woyqac9pW9LhPMm4DsHsQtHtuupcIV0/IzY/FdwUo1HQmZtDz5A9EKwqm1zprlCNykFNlVCqLT6DOBm6hvQZZS+rjns3BDXACU0oOU0m2U0llK6SyAkwBupJSebWd/g4i3DSGLAgrqB8AYt2zMnTaFyCXM46yUa1gp1wJtyXxfYNb8plchgklFtqM7FooqkoqEHS30XQDM8SuSE/J6fr3qW7/JvB/msdrpB8xw+hD7+wEMg3bcLEfgxkwYdMKfO40+E7iJKgCWCCGXAqAAQAj5CZjRQAIfUlYbQoamN68GClgVG8u1jptC2AJArbtKI3vhG9iz9pc90wBkyQ7NnF8qYWay9egUW2tSWatD/yYjqYRkZ1l20s4y7xN2ysN6QGwG5+NmISlLLg2gkzLbgkaiitNfgmmHv5IQcgpmOOj7ujEASwvYUqQTMjaqjdVAm2UV5zMJnF2rdNwUghcAfGnkhu24KKD5ooqRlIKpFguytUsqIbk0gHYFj11Ge4IrZe0pMZBWZC4PoP2G9n6ltnk67QYmaISZCimlQgOIgah5AMcopW8DcBGAKwHcCeD2OAe2mUkpslsDMJr7AADWtq/ecVOInDXfL21UXaWRvWS5cNWFYgn7JrM9i5pgpSAMg2JhudR2h6p8NmmHZi4WVcgSwe4Jd/0m0yfjZAK3rQGEtKEE+BIdYpXaLVjNqKpmwKCdNdoRNBIqAAghY4SQjxBC/poQ8n8AUGH2ATgC4Kd6McDNSDrhmDcAxwQU1hEMMFezTixw+yagEUsDYLV9gjJK+Qb2C0W1pyUCWCmIc+tVVOpGWzkXANMAzAl5vljCnolMg6bF+2TUagc+gCYVQYUG0H1MU6FhV9cVGkB3aTbL/COAKwAchBlZ9SCAnwTwo5TS98Q8tk2L1wlsawBNnMD5TBJ1S1h0wwnM2v8FCYBsSkG5rkPTDZy40L4Zph3Yyi6oA1lU+GJaQaakdEJ2fAA1re1a/WFtKAGnF4CYpLoHMxV2o8+CoJFmT+ollNJrAIAQ8gmYjt99lNJK7CPbxKQTkl1/HuCqgTZ1AjsTdSc+gJRsRhwxp2hQFFA2KYNS4NhSCXWdtr0Kb4ekLIFS4Oj5DQCth4AyWIVOSpOYL5Zww758wza8CagTHwAQXg+IrVJFqGL3YKZCp4y3YralEnSFZhqAvdShlOoATorJvzlpxaMBROgHAHgFQPsmINZoYrHITED+PgBmC2eN3nutAQDAq2fXoUgEu/LtFSjLZ5JYr2pYrVKsVzR/DYC7H51EAQH+bSgZtgYg7NRdgzmBhQYQD82WQtcRQtas/xMAGet3AoBSSsdiHd0mhZmAKKUghNgaQFMncKY7GgBgTlRHzplLpbAwUAB2o/d2V+HtwEr9vvraBvZOZkN7JYTBhObxNXOF76fFpLg8gE7j9P3aUDKEnbr7pBQJRc1w9cAo9XlMW4nQJ5VSKsRtG6QTEgwK1HWKpEKg6QYUiTSNsOFX6p1WBOQn/UAncMrRAFKKhG2jqY6O2QpJy8dx+Nw6Xr9rvO39sHM7tmpO8H7RRMwpb4cSdrBCz2cTdtlsL2KV2n2Yr4jvgSEEQPfoXd3RIcKuQGk5HnWDhpaCZvCTdqrDphBsYiQEGE031wB6XSaYmYCWNmod+R6Y1nR8xQAhwJ4JPwFgOoErdQOUdhal49eGkuGyUwu6gukD0O1oNaFddRchAGIg5SlBXNdpaCloRrd8AIDZaAIAxtKJQNMTWwkvl2o9LxPM1+Lp5NhMazq+pmPXeMbXdJZWZNR1ivWKOXF3qgGE5QFIxDFvCTqH1QJi+SoiD6C7iCc1Blgt/6pld9YNI5IGMJpOgFmJuqUBhHWV4lfCvYwAApya7UBn9YeY1lSqB/cyZsK0WDIn7o58AD5tKBksU3XQSxBvJhwnsNAA4kAIgBiw2xBaJqC6QZtGAAGmk3gs7W5l2C5sYgxrKsK/TL3WAFJd0wCaNztn13LZEgCdRAH5taFkiFo13YcJAKYBdNqJTuBGCIAYcLpQWRqATptGADHGPa0M24XV/wkTAPxk1csIIMARABIB9nhKN7QC798I0mLYtWQCoNM8AMA/G1it62KF2mWYE1i1Evj62c5yKyIEQAw4fWiZBmBE8gEAzoq2Uw2ATfxBOQCAVwPosQnIEgA7xzMdmbtMrcnpd+sH2383NAC/NpQMtaoJDaDLJGUJdZ1io6qJEhsxIARADDRoABGjgABeA+jUB2BO/EE5AOYxJBBiZg3vHG8vEatdmADoRv0hdq7BJqAu+gBYPSAfE5BZZkJMUt2EPScXSnWRYBcDQgDEAKvjwzQATY/mAwCcyczbFL5V8pnmTmDWwH7vRPuJWO3CXuxu+B7YOQZqALYPoAqg8yggAL7N4dWaLrqBdRlmKryg1oT9PwbEciUGbBOQ5QTWWjEBZRJQJNLxhJyP4AMAzMSaXpt/ACcKqBvRR+OZBPIpErj6ZgL5QsmctDvKA7AE9McfPop/e97d1PzIuQ3svXJb2/sWNMIEwIpax0haTFfdRlzRGPCagDQ9ugnondfs6IodeXc+g5+8aQ8KV1wUut373ziDy7aNdHy8VtkzkcWP3bAbb9/feSvon7hpD3ZJa4F/d0xAnWsAuaSMH79xD44tbbia/gDAFTtG8c6rt0xr64EgyWkA28Z6l6k+LAgBEAMpjxNYixgGCgC3XTqN2y6d7ngMiizhj3/yuqbb/fJbLu/4WO2QVCT86Xuv78q+3nP9boyvHA78Ox8GSkhnpbYJIfhfP9X8ugq6Q5LTAESEVfcRPoAYSHsygTXD6LmNXeDAC4BMQoQSbiaSsnnvarohIqxiQMxKMcBWmFXNMQFFzQMQdB8+D0BE6Wwu+JIhQgPoPkIAxEBCJpCIowHoBkUiog9A0H2YQDaoqNW/2eAzxoUG0H2EAIgBQoirLWTdoJAjRgEJug+fUyE0gM2F0ADiRcxKMZHmmpDohoGEMAH1jZRrEhGryM0ELwBEn4XuIwRATKQUyZUIJnwA/UOSiD2RdFIHSNB7+Kqxos9C9xECICbMJiSWE9igSIgooL7CMquFBrC5SAkNIFbErBQTbg3AEBpAn2F+AOED2FwIH0C8CAEQE7wTWGuhGJwgHpgAEFFAmwu+UqyIAuo+QgDEhNmInCsFITSAvsJyAYQGsLkQGkC8CAEQE6wROcA0AHGp+4mtAQg78qbCJQCEBtB1xKwUE2lFdpeCEBpAX2HJYCIKaHPBRwEJ7a37CAEQE+mE5GoJGbUctCAeWIE+oQFsLvgMemEC6j5iVooJdyawIZzAfcaOAhIawKaCECeHIyOEd9cRb0NMpBOyXQxOb6EctCAehA9g85JSJFBKXf4AQXcQAiAmUgkzD4BSirqIAuo7abGK3LSkFAkSEe9PHAgBEBNpxdQAdIMCgIgC6jOOBiAe+c1GUpYg5HY89G1WIoT8CiHkFULIi4SQP+rXOOKCTTilmukHEJnA/YWVFBChhJuPpCIJ301M9OWqEkLuAvAeANdRSquEkC3XSZslHrG+saIfQH8RpSA2L0lFQiYhBHcc9EsD+C8APkYprQIApfRcn8YRG7YGYAkA0Q+gv6TtMFAhADYbSUUSgjsmCKW09wcl5FkAXwbwDgAVAL9KKX0iYNu7AdwNANu3b7/p3nvvjXycjY0NjIyMdD7gNvjuaQ33PF/Fb78hjT98rIKfvSqJt80kenLsfp53v2h2zifWDTxyqo6fviIJsoUcisNwrx8+WUdSIrh1lykEhuGc/ejkvO+6666nKKUHvJ/HJlYJIfcD2OHzp49ax50EcCuAmwH8MyHkEuojjSil9wC4BwAOHDhAC4VC5DHMzc2hle27SfngGeD5p/G6118LPPY4rrrydSi8YaYnx+7nefeLKOf8c70ZSk8Zhntd8Pw+DOfsRxznHZsAoJS+LehvhJD/AuCL1oT/OCHEADAN4Hxc4+k1zATEfAAiDFQgEAwa/TJMfwnAXQBACHkdgCSApT6NJRZSHiewKAUhEAgGjX55Vj4F4FOEkBcA1AB8wM/8s5mxNYCKJQBEFJBAIBgw+iIAKKU1AD/bj2P3ClZ9siQ0AIFAMKCIWSkmvHkAIhFMIBAMGkIAxITXCSwSwQQCwaAhBEBMeAWA0AAEAsGgIQRATLDaMyVbAxCXWiAQDBZiVooJpgGsV4QGIBAIBhMhAGJClggSMkGpJnwAAoFgMBECIEbSimznAYhicAKBYNAQs1KMpBIyNqpmPwBRCkIgEAwaQgDESDohYaNaByAygQUCweAhBECMpBMyKnWzMbzIBBYIBIOGmJVihGUDA8IEJBAIBg8hAGKE1QMChAlIIBAMHkIAxEia62MqTEACgWDQELNSjLhMQEIDEAgEA4YQADGScmkAQgAIBILBQgiAGHH7AMSlFggEg4WYlWJERAEJBIJBRgiAGEkLE5BAIBhghACIEV4DENVABQLBoCEEQIwwH4AiERAiBIBAIBgshACIEWYCEqt/gUAwiAgBECPMBCS6gQkEgkFEzEwxkhIagEAgGGCEAIgRZgIS3cAEAsEgIgRAjKStxvBCAxAIBIOIEAAxwjQAUQhOIBAMImJmihFbAAgTkEAgGECEAIiRlDABCQSCAUYIgBixncDCBCQQCAYQMTPFCMsDEBqAQCAYRIQAiBERBioQCAYZIQBihNUCEhqAQCAYRIQAiJGUZQISzWAEAsEgImamGEkpEggRvQAEAsFgIgRAjBBCkFIkoQEIBIKBpC8zEyHkekLI9wkhzxJCniSE3NKPcfSCdEIWGoBAIBhI+rU0/SMAv08pvR7A/239viVJK0IACASCwaRfAoACGLP+Pw7gdJ/GETuZpCxKQQgEgoGEUEp7f1BCrgLwTQAEphC6jVK6ELDt3QDuBoDt27ffdO+990Y+zsbGBkZGRjofcAd897SGfIpg/5TcfOMuMQjn3WuG8ZyB4TzvYTxnoLPzvuuuu56ilB7wfh6bACCE3A9gh8+fPgrgrQAeopT+CyHkpwDcTSl9W7N9HjhwgD755JORxzA3N4dCoRB5+63CMJ73MJ4zMJznPYznDHR23oQQXwGgdDqoIMImdELIPwD4sPXr5wF8Iq5xCAQCgcCffvkATgO40/r/WwAc7tM4BAKBYGiJTQNown8C8BeEEAVABZaNXyAQCAS9oy8CgFL6CICb+nFsgUAgEJiIFFWBQCAYUoQAEAgEgiFFCACBQCAYUoQAEAgEgiGlL5nA7UIIOQ/AN2M4gGkASzENZ5AZxvMexnMGhvO8h/Gcgc7Oe4ZSepH3w00lAFqFEPKkX/bbVmcYz3sYzxkYzvMexnMG4jlvYQISCASCIUUIAIFAIBhStroAuKffA+gTw3jew3jOwHCe9zCeMxDDeW9pH4BAIBAIgtnqGoBAIBAIAhACQCAQCIaULSsACCHvIIQcIoQcIYT8Zr/HEweEkL2EkAcJIS8RQl4khHzY+nySEPItQshh6+dEv8fabQghMiHkGULIV63fLyaEPGbd788RQpL9HmO3IYTkCSFfIIS8Qgh5mRDyxq1+rwkh/9V6tl8ghHyWEJLeiveaEPIpQsg5QsgL3Ge+95aY/KV1/s8TQm5s97hbUgAQQmQAfwPgnQD2A/gZQsj+/o4qFjQA/41Suh/ArQB+yTrP3wTwbUrp5QC+bf2+1fgwgJe53/8ngD+jlF4G4AKAX+jLqOLlLwB8g1J6JYDrYJ7/lr3XhJDdAD4E4ACl9GoAMoCfxta81/8bwDs8nwXd23cCuNz6dzeAv233oFtSAAC4BcARSukxSmkNwL0A3tPnMXUdSukZSunT1v/XYU4Iu2Ge66etzT4N4Ef6M8J4IITsAfCDsDrJEUIIzMZCX7A22YrnPA7gzQA+CQCU0hqldAVb/F7DLFmfsXqHZAGcwRa815TShwEsez4OurfvAfAP1OT7APKEkJ3tHHerCoDdAE5wv5+0PtuyEEJmAdwA4DEA2ymlZ6w/nQWwvU/Dios/B/DrAAzr9ykAK5RSzfp9K97viwGcB/D3lunrE4SQHLbwvaaUngLwJwAWYU78qwCewta/14yge9u1+W2rCoChghAyAuBfAPyflNI1/m/UjPPdMrG+hJAfAnCOUvpUv8fSYxQANwL4W0rpDQBK8Jh7tuC9noC52r0YwC4AOTSaSYaCuO7tVhUApwDs5X7fY3225SCEJGBO/p+hlH7R+vg1phJaP8/1a3wx8CYA7yaEzMM07b0Fpm08b5kJgK15v08COEkpfcz6/QswBcJWvtdvA3CcUnqeUloH8EWY93+r32tG0L3t2vy2VQXAEwAut6IFkjAdR1/p85i6jmX7/iSAlymlf8r96SsAPmD9/wMAvtzrscUFpfQjlNI9lNJZmPf1AUrp+wA8COAnrM221DkDAKX0LIAThJArrI/eCuAlbOF7DdP0cyshJGs96+yct/S95gi6t18B8H4rGuhWAKucqag1KKVb8h+AdwF4FcBRAB/t93hiOsfbYaqFzwN41vr3Lpg28W8DOAzgfgCT/R5rTOdfAPBV6/+XAHgcwBEAnweQ6vf4Yjjf6wE8ad3vLwGY2Or3GsDvA3gFwAsA/hFAaiveawCfhennqMPU9n4h6N4CIDCjHI8COAgzSqqt44pSEAKBQDCkbFUTkEAgEAiaIASAQCAQDClCAAgEAsGQIgSAQCAQDClCAAgEAsGQIgSAYKghhOiEkGe5f6HF1AghHySEvL8Lx50nhEx3uh+BoBNEGKhgqCGEbFBKR/pw3HmY8dtLvT62QMAQGoBA4IO1Qv8jQshBQsjjhJDLrM9/jxDyq9b/P2T1YnieEHKv9dkkIeRL1mffJ4Rca30+RQi5z6pt/wmYyTzsWD9rHeNZQsj/a5UzFwhiRwgAwbCT8ZiA3sv9bZVSeg2Av4ZZgdTLbwK4gVJ6LYAPWp/9PoBnrM9+C8A/WJ//LoBHKKWvB/CvAPYBACHkKgDvBfAmSun1AHQA7+vuKQoE/ijNNxEItjRla+L147Pczz/z+fvzAD5DCPkSzNIMgFme48cBgFL6gLXyH4NZy//HrM//nRBywdr+rQBuAvCEWe4GGWytgm6CAUYIAIEgGBrwf8YPwpzYfxjARwkh17RxDALg05TSj7TxXYGgI4QJSCAI5r3cz+/xfyCESAD2UkofBPAbAMbx/7d3tzgRBUEUhc8NigQDAstWsHgMbIEtIGALs4BRk7AFgoQETUjAjx+BIpmMKMRrfjJBgqrzufc6LVrdVKdSDXvAA+MKJ8kxsKrpjYZ74Hz8P2Ea5AbTsK/TJIdj7SDJ0T+eSfpiBaDudpM8/fi+rarPVtD9JM/AGjjb2rcDLMZTjQFmVfWW5AqYj33vfI/zvQZukrwAj0yjjqmq1ySXwN0IlQ1wASz/+qDSNttApV/YpqkOvAKSpKasACSpKSsASWrKAJCkpgwASWrKAJCkpgwASWrqAym1/enzxHhbAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# obs = env.reset()\n","# a = env.step(action)\n","# print(obs ,'\\n New obs:',a)"],"metadata":{"id":"5fAsyCUrleeY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# env = make(\"football\", debug=True, configuration={\"save_video\": False, \"scenario_name\": \"11_vs_11_kaggle\", \"running_in_notebook\": True})\n","# env.render"],"metadata":{"id":"r58vLy9MzVKE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ena =env.reset() \n","# #dyo=simple_env.reset()\n","\n","# #print(ena.shape)\n","# print(ena[0])#olo to environment\n","# #pprint.pprint(ena[0])\n"],"metadata":{"id":"wMG5tesrzU6V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %%writefile submission.py\n","# from kaggle_environments.envs.football.helpers import *\n","\n","# ## @human_readable_agent wrapper modifies raw observations \n","# # provided by the environment:\n","# # https://github.com/google-research/football/blob/master/gfootball/doc/observation.md#raw-observations\n","# # into a form easier to work with by humans.\n","# # Following modifications are applied:\n","# # - Action, PlayerRole and GameMode enums are introduced.\n","# # - 'sticky_actions' are turned into a set of active actions (Action enum)\n","# #    see usage example below.\n","# # - 'game_mode' is turned into GameMode enum.\n","# # - 'designated' field is removed, as it always equals to 'active'\n","# #    when a single player is controlled on the team.\n","# # - 'left_team_roles'/'right_team_roles' are turned into PlayerRole enums.\n","# # - Action enum is to be returned by the agent function.\n","# @human_readable_agent\n","# def agent(obs):\n","#     # Make sure player is running.\n","#     if Action.Sprint not in obs['sticky_actions']:\n","#         return Action.Sprint\n","#     # We always control left team (observations and actions\n","#     # are mirrored appropriately by the environment).\n","#     controlled_player_pos = obs['left_team'][obs['active']]\n","#     # Does the player we control have the ball?\n","#     if obs['ball_owned_player'] == obs['active'] and obs['ball_owned_team'] == 0:  #EXEI PAIKTIS TIN MPALA KAI EINAI STIN ARISTERI OMADA\n","#         # Shot if we are 'close' to the goal (based on 'x' coordinate).\n","#         if controlled_player_pos[0] > 0.5:\n","#             return Action.Shot\n","#         # Run towards the goal otherwise.\n","#         return Action.Right\n","#     else:\n","#         # Run towards the ball.\n","#         if obs['ball'][0] > controlled_player_pos[0] + 0.05:\n","#             return Action.Right\n","#         if obs['ball'][0] < controlled_player_pos[0] - 0.05:\n","#             return Action.Left\n","#         if obs['ball'][1] > controlled_player_pos[1] + 0.05:\n","#             return Action.Bottom\n","#         if obs['ball'][1] < controlled_player_pos[1] - 0.05:\n","#             return Action.Top\n","#         # Try to take over the ball if close to the ball.\n","#         return Action.Slide"],"metadata":{"id":"IgzLAAGcvOB0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Set up the Environment.\n","# from kaggle_environments import make\n","# env = make(\"football\", configuration={\"save_video\": True, \"scenario_name\": \"11_vs_11_kaggle\", \"running_in_notebook\": True})\n","# output = env.run([\"/kaggle/working/submission.py\", \"do_nothing\"])[-1]\n","# print('Left player: reward = %s, status = %s, info = %s' % (output[0]['reward'], output[0]['status'], output[0]['info']))\n","# print('Right player: reward = %s, status = %s, info = %s' % (output[1]['reward'], output[1]['status'], output[1]['info']))\n","# env.render(mode=\"human\", width=800, height=600)"],"metadata":{"id":"Ez73Yfd9vOZ2"},"execution_count":null,"outputs":[]}]}