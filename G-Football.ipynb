{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"G-Football.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPzsNEdduxD6VLm+TwWWFX7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"JezRCSzQzmyy"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"AwiPWSjbujSz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649413069249,"user_tz":-180,"elapsed":64126,"user":{"displayName":"george mouts","userId":"12301814581979843830"}},"outputId":"92eab53e-6720-4002-f1bd-8977333aee36"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'kaggle-environments'...\n","remote: Enumerating objects: 4242, done.\u001b[K\n","remote: Counting objects: 100% (1022/1022), done.\u001b[K\n","remote: Compressing objects: 100% (326/326), done.\u001b[K\n","remote: Total 4242 (delta 817), reused 817 (delta 694), pack-reused 3220\u001b[K\n","Receiving objects: 100% (4242/4242), 11.38 MiB | 6.68 MiB/s, done.\n","Resolving deltas: 100% (2576/2576), done.\n","Processing /content/kaggle-environments\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.7) (4.3.3)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.7) (1.1.4)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.7) (1.21.5)\n","Collecting requests>=2.25.1\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (1.1.0)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (2.11.3)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (7.1.2)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (1.0.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.2->kaggle-environments==1.9.7) (2.0.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (4.11.3)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (5.4.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (21.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (3.10.0.2)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.1->kaggle-environments==1.9.7) (3.7.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (2.10)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (2.0.12)\n","Building wheels for collected packages: kaggle-environments\n","  Building wheel for kaggle-environments (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle-environments: filename=kaggle_environments-1.9.7-py3-none-any.whl size=1813045 sha256=4180e0f310166a2effecb2738f31a342729a5911c201628961df689b12f12dfe\n","  Stored in directory: /root/.cache/pip/wheels/67/f1/54/59176bd30840c0a045df67632e2e903095b3c02b64cb0a636c\n","Successfully built kaggle-environments\n","Installing collected packages: requests, kaggle-environments\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed kaggle-environments-1.9.7 requests-2.27.1\n","Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:15 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [82.3 kB]\n","Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [952 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,268 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [918 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,133 kB]\n","Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,831 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.9 kB]\n","Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [938 kB]\n","Get:26 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [884 kB]\n","Get:27 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,694 kB]\n","Get:28 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.2 kB]\n","Get:29 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,490 kB]\n","Get:30 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n","Fetched 15.6 MB in 4s (3,594 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  gir1.2-ibus-1.0 libcapnp-0.6.1 libdbus-1-dev libibus-1.0-5 libibus-1.0-dev\n","  libmirclient-dev libmirclient9 libmircommon-dev libmircommon7\n","  libmircookie-dev libmircookie2 libmircore-dev libmircore1 libmirprotobuf3\n","  libprotobuf-dev libprotobuf-lite10 libpulse-dev libpulse-mainloop-glib0\n","  libsdl2-dev libsdl2-gfx-1.0-0 libsdl2-ttf-2.0-0 libsndio-dev libudev-dev\n","  libxcursor-dev libxinerama-dev libxkbcommon-dev libxrandr-dev libxv-dev\n","  x11proto-randr-dev x11proto-xinerama-dev\n","Suggested packages:\n","  libsdl2-gfx-doc\n","The following NEW packages will be installed:\n","  gir1.2-ibus-1.0 libcapnp-0.6.1 libdbus-1-dev libibus-1.0-5 libibus-1.0-dev\n","  libmirclient-dev libmirclient9 libmircommon-dev libmircommon7\n","  libmircookie-dev libmircookie2 libmircore-dev libmircore1 libmirprotobuf3\n","  libprotobuf-dev libprotobuf-lite10 libpulse-dev libpulse-mainloop-glib0\n","  libsdl2-dev libsdl2-gfx-1.0-0 libsdl2-gfx-dev libsdl2-ttf-2.0-0\n","  libsdl2-ttf-dev libsndio-dev libudev-dev libxcursor-dev libxinerama-dev\n","  libxkbcommon-dev libxrandr-dev libxv-dev x11proto-randr-dev\n","  x11proto-xinerama-dev\n","0 upgraded, 32 newly installed, 0 to remove and 96 not upgraded.\n","Need to get 3,919 kB of archives.\n","After this operation, 24.9 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libibus-1.0-5 amd64 1.5.17-3ubuntu5.3 [133 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gir1.2-ibus-1.0 amd64 1.5.17-3ubuntu5.3 [66.5 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcapnp-0.6.1 amd64 0.6.1-1ubuntu1 [658 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdbus-1-dev amd64 1.12.2-1ubuntu1.2 [165 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libibus-1.0-dev amd64 1.5.17-3ubuntu5.3 [145 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore1 amd64 0.31.1-0ubuntu1 [26.5 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon7 amd64 0.31.1-0ubuntu1 [73.9 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-lite10 amd64 3.0.0-9.1ubuntu1 [97.7 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirprotobuf3 amd64 0.31.1-0ubuntu1 [127 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient9 amd64 0.31.1-0ubuntu1 [199 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore-dev amd64 0.31.1-0ubuntu1 [21.7 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-dev amd64 3.0.0-9.1ubuntu1 [959 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxkbcommon-dev amd64 0.8.2-1~ubuntu18.04.1 [150 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon-dev amd64 0.31.1-0ubuntu1 [13.9 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie2 amd64 0.31.1-0ubuntu1 [19.7 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie-dev amd64 0.31.1-0ubuntu1 [4,392 B]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient-dev amd64 0.31.1-0ubuntu1 [47.8 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-mainloop-glib0 amd64 1:11.1-1ubuntu7.11 [22.1 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-dev amd64 1:11.1-1ubuntu7.11 [81.5 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsndio-dev amd64 1.1.0-3 [13.3 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libudev-dev amd64 237-3ubuntu10.53 [19.1 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor-dev amd64 1:1.1.15-1 [26.5 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xinerama-dev all 2018.4-4 [2,628 B]\n","Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama-dev amd64 2:1.1.3-1 [8,404 B]\n","Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-randr-dev all 2018.4-4 [2,620 B]\n","Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr-dev amd64 2:1.5.1-1 [24.0 kB]\n","Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxv-dev amd64 2:1.0.11-1 [32.5 kB]\n","Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsdl2-dev amd64 2.0.8+dfsg1-1ubuntu1.18.04.4 [683 kB]\n","Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-gfx-1.0-0 amd64 1.0.4+dfsg-1 [29.9 kB]\n","Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-gfx-dev amd64 1.0.4+dfsg-1 [29.8 kB]\n","Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-ttf-2.0-0 amd64 2.0.14+dfsg1-2 [14.8 kB]\n","Get:32 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-ttf-dev amd64 2.0.14+dfsg1-2 [19.7 kB]\n","Fetched 3,919 kB in 0s (8,930 kB/s)\n","Extracting templates from packages: 100%\n","Selecting previously unselected package libibus-1.0-5:amd64.\n","(Reading database ... 156210 files and directories currently installed.)\n","Preparing to unpack .../00-libibus-1.0-5_1.5.17-3ubuntu5.3_amd64.deb ...\n","Unpacking libibus-1.0-5:amd64 (1.5.17-3ubuntu5.3) ...\n","Selecting previously unselected package gir1.2-ibus-1.0:amd64.\n","Preparing to unpack .../01-gir1.2-ibus-1.0_1.5.17-3ubuntu5.3_amd64.deb ...\n","Unpacking gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu5.3) ...\n","Selecting previously unselected package libcapnp-0.6.1:amd64.\n","Preparing to unpack .../02-libcapnp-0.6.1_0.6.1-1ubuntu1_amd64.deb ...\n","Unpacking libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n","Selecting previously unselected package libdbus-1-dev:amd64.\n","Preparing to unpack .../03-libdbus-1-dev_1.12.2-1ubuntu1.2_amd64.deb ...\n","Unpacking libdbus-1-dev:amd64 (1.12.2-1ubuntu1.2) ...\n","Selecting previously unselected package libibus-1.0-dev:amd64.\n","Preparing to unpack .../04-libibus-1.0-dev_1.5.17-3ubuntu5.3_amd64.deb ...\n","Unpacking libibus-1.0-dev:amd64 (1.5.17-3ubuntu5.3) ...\n","Selecting previously unselected package libmircore1:amd64.\n","Preparing to unpack .../05-libmircore1_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircore1:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmircommon7:amd64.\n","Preparing to unpack .../06-libmircommon7_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libprotobuf-lite10:amd64.\n","Preparing to unpack .../07-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n","Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n","Selecting previously unselected package libmirprotobuf3:amd64.\n","Preparing to unpack .../08-libmirprotobuf3_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmirclient9:amd64.\n","Preparing to unpack .../09-libmirclient9_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmircore-dev:amd64.\n","Preparing to unpack .../10-libmircore-dev_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libprotobuf-dev:amd64.\n","Preparing to unpack .../11-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n","Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n","Selecting previously unselected package libxkbcommon-dev:amd64.\n","Preparing to unpack .../12-libxkbcommon-dev_0.8.2-1~ubuntu18.04.1_amd64.deb ...\n","Unpacking libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\n","Selecting previously unselected package libmircommon-dev:amd64.\n","Preparing to unpack .../13-libmircommon-dev_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmircookie2:amd64.\n","Preparing to unpack .../14-libmircookie2_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmircookie-dev:amd64.\n","Preparing to unpack .../15-libmircookie-dev_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmirclient-dev:amd64.\n","Preparing to unpack .../16-libmirclient-dev_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libpulse-mainloop-glib0:amd64.\n","Preparing to unpack .../17-libpulse-mainloop-glib0_1%3a11.1-1ubuntu7.11_amd64.deb ...\n","Unpacking libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.11) ...\n","Selecting previously unselected package libpulse-dev:amd64.\n","Preparing to unpack .../18-libpulse-dev_1%3a11.1-1ubuntu7.11_amd64.deb ...\n","Unpacking libpulse-dev:amd64 (1:11.1-1ubuntu7.11) ...\n","Selecting previously unselected package libsndio-dev:amd64.\n","Preparing to unpack .../19-libsndio-dev_1.1.0-3_amd64.deb ...\n","Unpacking libsndio-dev:amd64 (1.1.0-3) ...\n","Selecting previously unselected package libudev-dev:amd64.\n","Preparing to unpack .../20-libudev-dev_237-3ubuntu10.53_amd64.deb ...\n","Unpacking libudev-dev:amd64 (237-3ubuntu10.53) ...\n","Selecting previously unselected package libxcursor-dev:amd64.\n","Preparing to unpack .../21-libxcursor-dev_1%3a1.1.15-1_amd64.deb ...\n","Unpacking libxcursor-dev:amd64 (1:1.1.15-1) ...\n","Selecting previously unselected package x11proto-xinerama-dev.\n","Preparing to unpack .../22-x11proto-xinerama-dev_2018.4-4_all.deb ...\n","Unpacking x11proto-xinerama-dev (2018.4-4) ...\n","Selecting previously unselected package libxinerama-dev:amd64.\n","Preparing to unpack .../23-libxinerama-dev_2%3a1.1.3-1_amd64.deb ...\n","Unpacking libxinerama-dev:amd64 (2:1.1.3-1) ...\n","Selecting previously unselected package x11proto-randr-dev.\n","Preparing to unpack .../24-x11proto-randr-dev_2018.4-4_all.deb ...\n","Unpacking x11proto-randr-dev (2018.4-4) ...\n","Selecting previously unselected package libxrandr-dev:amd64.\n","Preparing to unpack .../25-libxrandr-dev_2%3a1.5.1-1_amd64.deb ...\n","Unpacking libxrandr-dev:amd64 (2:1.5.1-1) ...\n","Selecting previously unselected package libxv-dev:amd64.\n","Preparing to unpack .../26-libxv-dev_2%3a1.0.11-1_amd64.deb ...\n","Unpacking libxv-dev:amd64 (2:1.0.11-1) ...\n","Selecting previously unselected package libsdl2-dev:amd64.\n","Preparing to unpack .../27-libsdl2-dev_2.0.8+dfsg1-1ubuntu1.18.04.4_amd64.deb ...\n","Unpacking libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\n","Selecting previously unselected package libsdl2-gfx-1.0-0:amd64.\n","Preparing to unpack .../28-libsdl2-gfx-1.0-0_1.0.4+dfsg-1_amd64.deb ...\n","Unpacking libsdl2-gfx-1.0-0:amd64 (1.0.4+dfsg-1) ...\n","Selecting previously unselected package libsdl2-gfx-dev:amd64.\n","Preparing to unpack .../29-libsdl2-gfx-dev_1.0.4+dfsg-1_amd64.deb ...\n","Unpacking libsdl2-gfx-dev:amd64 (1.0.4+dfsg-1) ...\n","Selecting previously unselected package libsdl2-ttf-2.0-0:amd64.\n","Preparing to unpack .../30-libsdl2-ttf-2.0-0_2.0.14+dfsg1-2_amd64.deb ...\n","Unpacking libsdl2-ttf-2.0-0:amd64 (2.0.14+dfsg1-2) ...\n","Selecting previously unselected package libsdl2-ttf-dev:amd64.\n","Preparing to unpack .../31-libsdl2-ttf-dev_2.0.14+dfsg1-2_amd64.deb ...\n","Unpacking libsdl2-ttf-dev:amd64 (2.0.14+dfsg1-2) ...\n","Setting up libdbus-1-dev:amd64 (1.12.2-1ubuntu1.2) ...\n","Setting up libxcursor-dev:amd64 (1:1.1.15-1) ...\n","Setting up libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\n","Setting up libsdl2-gfx-1.0-0:amd64 (1.0.4+dfsg-1) ...\n","Setting up libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.11) ...\n","Setting up libpulse-dev:amd64 (1:11.1-1ubuntu7.11) ...\n","Setting up libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libsndio-dev:amd64 (1.1.0-3) ...\n","Setting up libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n","Setting up x11proto-xinerama-dev (2018.4-4) ...\n","Setting up x11proto-randr-dev (2018.4-4) ...\n","Setting up libxinerama-dev:amd64 (2:1.1.3-1) ...\n","Setting up libxv-dev:amd64 (2:1.0.11-1) ...\n","Setting up libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n","Setting up libibus-1.0-5:amd64 (1.5.17-3ubuntu5.3) ...\n","Setting up libsdl2-ttf-2.0-0:amd64 (2.0.14+dfsg1-2) ...\n","Setting up libmircore1:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n","Setting up libudev-dev:amd64 (237-3ubuntu10.53) ...\n","Setting up gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu5.3) ...\n","Setting up libxrandr-dev:amd64 (2:1.5.1-1) ...\n","Setting up libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n","Setting up libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libibus-1.0-dev:amd64 (1.5.17-3ubuntu5.3) ...\n","Setting up libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\n","Setting up libsdl2-ttf-dev:amd64 (2.0.14+dfsg1-2) ...\n","Setting up libsdl2-gfx-dev:amd64 (1.0.4+dfsg-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Cloning into 'football'...\n","remote: Enumerating objects: 2908, done.\u001b[K\n","remote: Counting objects: 100% (36/36), done.\u001b[K\n","remote: Compressing objects: 100% (22/22), done.\u001b[K\n","remote: Total 2908 (delta 10), reused 23 (delta 7), pack-reused 2872\u001b[K\n","Receiving objects: 100% (2908/2908), 27.11 MiB | 21.24 MiB/s, done.\n","Resolving deltas: 100% (1654/1654), done.\n","--2022-04-08 10:17:27--  https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.8.so\n","Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.193.128, 172.217.204.128, 172.217.203.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.193.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 45403632 (43M) [application/octet-stream]\n","Saving to: ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’\n","\n","football/third_part 100%[===================>]  43.30M   132MB/s    in 0.3s    \n","\n","2022-04-08 10:17:27 (132 MB/s) - ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’ saved [45403632/45403632]\n","\n","Processing /content/football\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting pygame==1.9.6\n","  Downloading pygame-1.9.6-cp37-cp37m-manylinux1_x86_64.whl (11.4 MB)\n","\u001b[K     |████████████████████████████████| 11.4 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (4.1.2.30)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (1.4.1)\n","Requirement already satisfied: gym>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (0.17.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (1.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (0.37.1)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.3.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.21.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.11.0->gfootball==2.8) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->gfootball==2.8) (1.15.0)\n","Building wheels for collected packages: gfootball\n","  Building wheel for gfootball (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gfootball: filename=gfootball-2.8-cp37-cp37m-linux_x86_64.whl size=38781744 sha256=8318993e9c45c98917d1131d788ced502249e2b02bacf2e81e8f651cef956349\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ieu48zc8/wheels/bb/c2/92/82a23d0c207f5497a23f4316675eb1629e6be474bd2c3be61a\n","Successfully built gfootball\n","Installing collected packages: pygame, gfootball\n","Successfully installed gfootball-2.8 pygame-1.9.6\n"]}],"source":["#https://www.kaggle.com/piotrstanczyk/gfootball-template-bot  G-FOOTBALL TEMPLATE BOT\n","# Install:\n","# Kaggle environments.\n","!git clone https://github.com/Kaggle/kaggle-environments.git\n","!cd kaggle-environments && pip install .\n","\n","# GFootball environment.\n","!apt-get update -y\n","!apt-get install -y libsdl2-gfx-dev libsdl2-ttf-dev\n","\n","# Make sure that the Branch in git clone and in wget call matches !!\n","!git clone -b v2.8 https://github.com/google-research/football.git\n","!mkdir -p football/third_party/gfootball_engine/lib\n","\n","!wget https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.8.so -O football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so\n","!cd football && GFOOTBALL_USE_PREBUILT_SO=1 pip3 install ."]},{"cell_type":"markdown","source":["# All the imports"],"metadata":{"id":"WVKirdPZ7joO"}},{"cell_type":"code","source":["from gfootball.env.football_env import FootballEnv\n","from kaggle_environments import make\n","from gfootball.env.config import Config\n","from gfootball.env.football_env import FootballEnv\n","\n","#import dqn libraries\n","import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim \n","import numpy as np\n","import pandas as pd\n","import itertools\n","import random\n","from collections import deque\n","import matplotlib.pyplot as plt\n","\n","#import env \n","import gym\n","import gfootball \n","\n","#env_name = \"GFootballBase-v0\"\n","#print(env_name)"],"metadata":{"id":"Y8iVn65JzVqw","executionInfo":{"status":"ok","timestamp":1649413077820,"user_tz":-180,"elapsed":8589,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Initialize variables"],"metadata":{"id":"6DnksAK4BzPW"}},{"cell_type":"code","source":["BUFFERSIZE = 100000  #how many experiences will store |ReplayBufferSize=100,000\n","REWBUFFERSIZE = 100   #how many episode rewards will store|RewardBufferSize =100\n","MINREPLAYSIZE= 3000 # Episode is 3000 steps\n","GAMMA = 0.04\n","EPSILON =0.03\n","TARGET_UPDATE_FREQ = 25\n","\n","EPSILON_START=0.5\n","EPSILON_END =0.01\n","EPSILON_DECAY=0.001\n","\n","BATCH_SIZE = 3\n"],"metadata":{"id":"Q1ygyd2KEjM2","executionInfo":{"status":"ok","timestamp":1649413077822,"user_tz":-180,"elapsed":11,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Deep Q Network Model"],"metadata":{"id":"xTTdFh2aEFjF"}},{"cell_type":"code","source":["class DQN(nn.Module):\n","  def __init__(self,env):\n","    super(DQN,self).__init__()\n","    input_dims = int(np.prod(env.observation_space.shape)) #neurons input layer = number of observations\n","    self.net =nn.Sequential(nn.Linear(input_dims,200), \n","                            nn.Tanh(),\n","                            nn.Linear(200,env.action_space.n)) # neurons outpul layer = number of observations \n","                            \n","  def forward(self,x):\n","    return self.net(x) #use the dqnetwork\n","\n","  def act(self,obs): #returns the best acrtion/highest value action of the net \n","    obs_t =torch.as_tensor(obs,dtype=torch.float32)\n","    q_values=self(obs_t.unsqueeze(0)) # make tensor a batch dimension\n","\n","    max_q_index = torch.argmax(q_values,dim=1)[0]   # taking action with highest q value\n","    action = max_q_index.detach().item() # making tensor to integer which represents action \n","    \n","    return action \n","\n"],"metadata":{"id":"to44sPKhEETf","executionInfo":{"status":"ok","timestamp":1649413077823,"user_tz":-180,"elapsed":11,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Agent "],"metadata":{"id":"Elknm2VGEhMX"}},{"cell_type":"code","source":["class Agent() : \n","  def __init__(self,gamma,epsilon):\n","    self.gamma =gamma\n","    self.epsilon =epsilon\n","    \n","    self.ReplayBuffer = deque(maxlen=BUFFERSIZE) #Store experiences \n","    self.RewBuffer = deque(maxlen=REWBUFFERSIZE) #Store rewards\n","    \n","    self.online_net = DQN(env)   \n","    self.target_net = DQN(env)  \n","\n","    self.target_net.load_state_dict(self.online_net.state_dict())\n","\n","\n","  def transition(self,obs,new_obs,action,reward ,done): # should be tuple ? \n","    self.obs =obs\n","    self.action=action\n","    self.reward =reward \n","    self.done=done\n","    #self.info =info\n","    self.new_obs =new_obs\n","    TransitionTuple= (obs,new_obs,action,reward,done)\n","    #print(\"class\",TransitionTuple)\n","    return TransitionTuple\n","\n","  def learn(self,loss):\n","    \n","    self.loss=loss\n","    self.optimizer=torch.optim.Adam(self.online_net.parameters(),lr =1e-3) \n","    self.optimizer.zero_grad()\n","    self.loss.backward()\n","    self.optimizer.step()\n","\n","  def Arrays_To_Tensors(self,transitions): #make arrays -> pytorch tensors\n","    self.transitions=transitions\n","\n","    #Store observations as arrays\n","    obses = np.asarray([t[0] for t in transitions])\n","    new_obses = np.asarray([t[1]for t in transitions])\n","    actions = np.asarray([t[2] for t in transitions])\n","    rewards = np.asarray([t[3] for t in transitions])\n","    dones = np.asarray([t[4] for t in transitions])\n","  \n","    #Convert observation arrays to pytorch tensors\n","    obses_t=torch.as_tensor(obses,dtype=torch.float32)\n","    actions_t = torch.as_tensor(actions,dtype=torch.int64).unsqueeze(-1) #making batch dimension to one dimension\n","    rewards_t = torch.as_tensor(rewards,dtype= torch.float32).unsqueeze(-1)\n","    dones_t = torch.as_tensor(dones,dtype= torch.float32).unsqueeze(-1)\n","    new_obses_t = torch.as_tensor(new_obses,dtype= torch.float32)\n","\n","    return obses_t,actions_t,rewards_t,dones_t,new_obses_t\n","\n","\n"],"metadata":{"id":"1IRll4ZoEi7c","executionInfo":{"status":"ok","timestamp":1649415024815,"user_tz":-180,"elapsed":303,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"knTlNNXLoR_n","executionInfo":{"status":"ok","timestamp":1649413078127,"user_tz":-180,"elapsed":17,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"I7CxKikMoSgK","executionInfo":{"status":"ok","timestamp":1649413078626,"user_tz":-180,"elapsed":513,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# All Prints"],"metadata":{"id":"2MA4EXOMYaII"}},{"cell_type":"code","source":["class All_prints():\n","  \n","  def __init___(self,step):\n","    self.step=step\n","    #self.RewBuffer = RewBuffer\n","    self.reward=reward\n","\n","  def printstats(self,step,RewBuffer,eps_reward):  #Kaleitai otan ginei done , diladi otan teleiosei ena paixnidi\n","    self.step=step\n","    self.RewBuffer=RewBuffer\n","    self.eps_reward=eps_reward\n","    print(\"-->Episode:\",self.step%3000 + 1 ,\"\\t\",\"Episode Reward:\",self.eps_reward,\"<--\")\n","    print(\"Step\",step)\n","    print(\"lista apo rewards mexri tora\" ,self.RewBuffer)\n","    print(\"Avg reward\", np.mean(self.RewBuffer))\n","    print(\"---------------------------------------------------\")\n","\n","  def print_who_scored(self, reward):\n","    self.reward=reward\n","    if(self.reward==-1):\n","      print(\"opponent team scored\")\n","    elif(self.reward==1):\n","      print(\"our team scored !!!\")\n"," \n","  def rew_graph(self,RewBuffer,step,num_of_eps):\n","      self.RewBuffer=RewBuffer\n","      self.step=step\n","      self.num_of_eps=num_of_eps\n","      episode=self.step%3000\n","      eps_list=list(range(1,self.num_of_eps+1))#pairnei to proto , den pairnei to teleytaio\n","      #print(agent.RewBuffer,eps_list)\n","      plt.plot(eps_list,self.RewBuffer)\n","      plt.xlabel('Episode')\n","      plt.ylabel('Rewards')\n","      plt.grid(True)\n","      plt.show()"],"metadata":{"id":"9kC3LFnSmkGC","executionInfo":{"status":"ok","timestamp":1649414474328,"user_tz":-180,"elapsed":515,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Create Environment -- Main \n"],"metadata":{"id":"ZCAOuUjA8ZpZ"}},{"cell_type":"code","source":["#if __name__ =='main': \n","#TO DO:MAKE A CLASS FOR LEARNING\n","\n","env = gym.make(\"GFootball-11_vs_11_kaggle-simple115v2-v0\") #List with the 115 states \n","eps_reward =0.0\n","\n","obs = env.reset()\n","\n","#CREATE OBJECTS \n","agent=Agent(GAMMA,EPSILON) #Agent class\n","all_prints=All_prints() # print class\n","\n","#Initialize ReplayBuffer # TO DO : MAKE IT A CLASS\n","\n","for i in range(MINREPLAYSIZE): \n","  action =env.action_space.sample() #random action \n","\n","  new_obs ,reward,done ,info = env.step(action) \n","\n","  transition = agent.transition(obs,new_obs,action,reward ,done) #obs ,action ,reward , done ,info , new_obs  PROSEKSE TO MALLON LATHOS\n","  agent.ReplayBuffer.append(transition)  #Fill Replay Buffer with transitions\n","  obs=new_obs\n","\n","  if(done):  \n","    obs=env.reset()\n","\n","\n","# MAIN TRAIN LOOP\n","obs =env.reset()\n","c= 0\n","num_of_eps= 50     #GIVE NUMBER OF EPISODES\n","\n","for step in range((3000 * num_of_eps) + num_of_eps ):# play 3000 steps = 1 match = 1 episode\n","  \n","  \n","  #epsilon greedy\n","  epsilon = np.interp(step,[0,EPSILON_DECAY],[EPSILON_START,EPSILON_END]) #Epsilon start->end with epsilon decays steps from 100% random actions->2% rnd actions\n","  rnd_sample = random.random()\n","  \n","  if rnd_sample <= epsilon: #random action |explore|\n","    action = env.action_space.sample()\n","  else:  \n","    action = agent.online_net.act(obs) #best action |exploit|     YPARXEI THEMA EDO PERA , POU GEMIZEI TO ONLINE NET ??\n"," \n","  \n","  new_obs,reward,done,info = env.step(action)\n","  #print who scored\n","  all_prints.print_who_scored(reward)\n","  transition = agent.transition(obs,new_obs,action,reward ,done) #fill Replaybuffer with transitions \n","  agent.ReplayBuffer.append(transition) \n","  obs=new_obs\n","\n","  eps_reward = eps_reward+reward\n","  \n","  if (done) : \n","    obs=env.reset()  \n","    agent.RewBuffer.append(eps_reward)\n","    #Print Resume when an episode ends\n","    all_prints.printstats(step,agent.RewBuffer,eps_reward)#balto sto rewgraph\n","    if(step == (3000 * num_of_eps)+num_of_eps -1):\n","      all_prints.rew_graph(agent.RewBuffer,step,num_of_eps)\n","    eps_reward =0.0 \n","\n","\n","# Start Gradient Step \n","  transitions =random.sample(agent.ReplayBuffer , BATCH_SIZE) #sample batch_size number of random transitions from Replaybuffer ,\n","                                                              # Replay buffer have been filled earlier\n","\n"," #Store arrays and conver them to pytorch sensors\n","  obses_t,actions_t,rewards_t,dones_t,new_obses_t = agent.Arrays_To_Tensors(transitions)\n","\n","  #Compute Targets\n","  target_q_values = agent.target_net(new_obses_t)# q values for each observation \n","  max_target_q_values = target_q_values.max(dim=1,keepdim=True)[0] #take the maximum value in dim =1 , discard all the rest dimensions\n","                                                                  #max returns tuple , first element is highest values and second is the index to them \n","\n","  targets = rewards_t +GAMMA + (1-dones_t) * max_target_q_values #deepmind_atari_paper dqn learn with replay\n","                                                                #if its a terminal state: dones_t =1 -> targets= rewards_t\n","\n","  #Compute Loss\n","  q_values = agent.online_net(obses_t)\n","  action_q_values =torch.gather(input=q_values,dim=1,index=actions_t)\n","  loss=nn.functional.smooth_l1_loss(action_q_values,targets)\n","\n","  #Gradient Descent \n","  agent.learn(loss)\n","  '''optimizer=torch.optim.Adam(agent.online_net.parameters(),lr =0.02)\n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()'''\n","\n","  #Update the target network, copying all weights and biases in DQN\n","  if step% TARGET_UPDATE_FREQ == 0:   #Update target network based on online network\n","    agent.target_net.load_state_dict(agent.online_net.state_dict())\n","\n","  \n","  \n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Elq8YWsx8d1C","executionInfo":{"status":"ok","timestamp":1649417482852,"user_tz":-180,"elapsed":2454773,"user":{"displayName":"george mouts","userId":"12301814581979843830"}},"outputId":"0673a349-8879-4c36-f8ec-a0272e3ad0e5"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["opponent team scored\n","-->Episode: 1 \t Episode Reward: -1.0 <--\n","Step 3000\n","lista apo rewards mexri tora deque([-1.0], maxlen=100)\n","Avg reward -1.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 2 \t Episode Reward: -4.0 <--\n","Step 6001\n","lista apo rewards mexri tora deque([-1.0, -4.0], maxlen=100)\n","Avg reward -2.5\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 3 \t Episode Reward: -2.0 <--\n","Step 9002\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0], maxlen=100)\n","Avg reward -2.3333333333333335\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 4 \t Episode Reward: -4.0 <--\n","Step 12003\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0], maxlen=100)\n","Avg reward -2.75\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 5 \t Episode Reward: -3.0 <--\n","Step 15004\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0], maxlen=100)\n","Avg reward -2.8\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 6 \t Episode Reward: -3.0 <--\n","Step 18005\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0], maxlen=100)\n","Avg reward -2.8333333333333335\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 7 \t Episode Reward: -5.0 <--\n","Step 21006\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0], maxlen=100)\n","Avg reward -3.142857142857143\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 8 \t Episode Reward: -6.0 <--\n","Step 24007\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0], maxlen=100)\n","Avg reward -3.5\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 9 \t Episode Reward: -4.0 <--\n","Step 27008\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0], maxlen=100)\n","Avg reward -3.5555555555555554\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 10 \t Episode Reward: -3.0 <--\n","Step 30009\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0], maxlen=100)\n","Avg reward -3.5\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 11 \t Episode Reward: -4.0 <--\n","Step 33010\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0], maxlen=100)\n","Avg reward -3.5454545454545454\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 12 \t Episode Reward: -2.0 <--\n","Step 36011\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0], maxlen=100)\n","Avg reward -3.4166666666666665\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 13 \t Episode Reward: -2.0 <--\n","Step 39012\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0], maxlen=100)\n","Avg reward -3.3076923076923075\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 14 \t Episode Reward: -5.0 <--\n","Step 42013\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0], maxlen=100)\n","Avg reward -3.4285714285714284\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 15 \t Episode Reward: -2.0 <--\n","Step 45014\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0], maxlen=100)\n","Avg reward -3.3333333333333335\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 16 \t Episode Reward: -3.0 <--\n","Step 48015\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0], maxlen=100)\n","Avg reward -3.3125\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 17 \t Episode Reward: -1.0 <--\n","Step 51016\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0], maxlen=100)\n","Avg reward -3.176470588235294\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 18 \t Episode Reward: -5.0 <--\n","Step 54017\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0], maxlen=100)\n","Avg reward -3.2777777777777777\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 19 \t Episode Reward: -1.0 <--\n","Step 57018\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0], maxlen=100)\n","Avg reward -3.1578947368421053\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 20 \t Episode Reward: -3.0 <--\n","Step 60019\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0], maxlen=100)\n","Avg reward -3.15\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 21 \t Episode Reward: -4.0 <--\n","Step 63020\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0], maxlen=100)\n","Avg reward -3.1904761904761907\n","---------------------------------------------------\n","-->Episode: 22 \t Episode Reward: 0.0 <--\n","Step 66021\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0], maxlen=100)\n","Avg reward -3.0454545454545454\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 23 \t Episode Reward: -2.0 <--\n","Step 69022\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0], maxlen=100)\n","Avg reward -3.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 24 \t Episode Reward: -4.0 <--\n","Step 72023\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0], maxlen=100)\n","Avg reward -3.0416666666666665\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 25 \t Episode Reward: -5.0 <--\n","Step 75024\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0], maxlen=100)\n","Avg reward -3.12\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 26 \t Episode Reward: -4.0 <--\n","Step 78025\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0], maxlen=100)\n","Avg reward -3.1538461538461537\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 27 \t Episode Reward: -4.0 <--\n","Step 81026\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0], maxlen=100)\n","Avg reward -3.185185185185185\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 28 \t Episode Reward: -3.0 <--\n","Step 84027\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0], maxlen=100)\n","Avg reward -3.1785714285714284\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 29 \t Episode Reward: -3.0 <--\n","Step 87028\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0], maxlen=100)\n","Avg reward -3.1724137931034484\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 30 \t Episode Reward: -3.0 <--\n","Step 90029\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0], maxlen=100)\n","Avg reward -3.1666666666666665\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 31 \t Episode Reward: -3.0 <--\n","Step 93030\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0], maxlen=100)\n","Avg reward -3.161290322580645\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 32 \t Episode Reward: -3.0 <--\n","Step 96031\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0], maxlen=100)\n","Avg reward -3.15625\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 33 \t Episode Reward: -2.0 <--\n","Step 99032\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0], maxlen=100)\n","Avg reward -3.121212121212121\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 34 \t Episode Reward: -1.0 <--\n","Step 102033\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0], maxlen=100)\n","Avg reward -3.0588235294117645\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 35 \t Episode Reward: -3.0 <--\n","Step 105034\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0], maxlen=100)\n","Avg reward -3.057142857142857\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 36 \t Episode Reward: -2.0 <--\n","Step 108035\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0], maxlen=100)\n","Avg reward -3.0277777777777777\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 37 \t Episode Reward: -1.0 <--\n","Step 111036\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0], maxlen=100)\n","Avg reward -2.972972972972973\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 38 \t Episode Reward: -2.0 <--\n","Step 114037\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0], maxlen=100)\n","Avg reward -2.9473684210526314\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 39 \t Episode Reward: -1.0 <--\n","Step 117038\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0], maxlen=100)\n","Avg reward -2.8974358974358974\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 40 \t Episode Reward: -1.0 <--\n","Step 120039\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0, -1.0], maxlen=100)\n","Avg reward -2.85\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 41 \t Episode Reward: -2.0 <--\n","Step 123040\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0, -1.0, -2.0], maxlen=100)\n","Avg reward -2.8292682926829267\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 42 \t Episode Reward: -2.0 <--\n","Step 126041\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0], maxlen=100)\n","Avg reward -2.8095238095238093\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 43 \t Episode Reward: -3.0 <--\n","Step 129042\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, -3.0], maxlen=100)\n","Avg reward -2.813953488372093\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 44 \t Episode Reward: -2.0 <--\n","Step 132043\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.7954545454545454\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 45 \t Episode Reward: -4.0 <--\n","Step 135044\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, -3.0, -2.0, -4.0], maxlen=100)\n","Avg reward -2.8222222222222224\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 46 \t Episode Reward: -1.0 <--\n","Step 138045\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, -3.0, -2.0, -4.0, -1.0], maxlen=100)\n","Avg reward -2.782608695652174\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 47 \t Episode Reward: -2.0 <--\n","Step 141046\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, -3.0, -2.0, -4.0, -1.0, -2.0], maxlen=100)\n","Avg reward -2.765957446808511\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 48 \t Episode Reward: -3.0 <--\n","Step 144047\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, -3.0, -2.0, -4.0, -1.0, -2.0, -3.0], maxlen=100)\n","Avg reward -2.7708333333333335\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 49 \t Episode Reward: -4.0 <--\n","Step 147048\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, -3.0, -2.0, -4.0, -1.0, -2.0, -3.0, -4.0], maxlen=100)\n","Avg reward -2.795918367346939\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 50 \t Episode Reward: -5.0 <--\n","Step 150049\n","lista apo rewards mexri tora deque([-1.0, -4.0, -2.0, -4.0, -3.0, -3.0, -5.0, -6.0, -4.0, -3.0, -4.0, -2.0, -2.0, -5.0, -2.0, -3.0, -1.0, -5.0, -1.0, -3.0, -4.0, 0.0, -2.0, -4.0, -5.0, -4.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.0, -1.0, -3.0, -2.0, -1.0, -2.0, -1.0, -1.0, -2.0, -2.0, -3.0, -2.0, -4.0, -1.0, -2.0, -3.0, -4.0, -5.0], maxlen=100)\n","Avg reward -2.84\n","---------------------------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# obs = env.reset()\n","# a = env.step(action)\n","# print(obs ,'\\n New obs:',a)"],"metadata":{"id":"5fAsyCUrleeY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# env = make(\"football\", debug=True, configuration={\"save_video\": False, \"scenario_name\": \"11_vs_11_kaggle\", \"running_in_notebook\": True})\n","# env.render"],"metadata":{"id":"r58vLy9MzVKE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ena =env.reset() \n","# #dyo=simple_env.reset()\n","\n","# #print(ena.shape)\n","# print(ena[0])#olo to environment\n","# #pprint.pprint(ena[0])\n"],"metadata":{"id":"wMG5tesrzU6V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %%writefile submission.py\n","# from kaggle_environments.envs.football.helpers import *\n","\n","# ## @human_readable_agent wrapper modifies raw observations \n","# # provided by the environment:\n","# # https://github.com/google-research/football/blob/master/gfootball/doc/observation.md#raw-observations\n","# # into a form easier to work with by humans.\n","# # Following modifications are applied:\n","# # - Action, PlayerRole and GameMode enums are introduced.\n","# # - 'sticky_actions' are turned into a set of active actions (Action enum)\n","# #    see usage example below.\n","# # - 'game_mode' is turned into GameMode enum.\n","# # - 'designated' field is removed, as it always equals to 'active'\n","# #    when a single player is controlled on the team.\n","# # - 'left_team_roles'/'right_team_roles' are turned into PlayerRole enums.\n","# # - Action enum is to be returned by the agent function.\n","# @human_readable_agent\n","# def agent(obs):\n","#     # Make sure player is running.\n","#     if Action.Sprint not in obs['sticky_actions']:\n","#         return Action.Sprint\n","#     # We always control left team (observations and actions\n","#     # are mirrored appropriately by the environment).\n","#     controlled_player_pos = obs['left_team'][obs['active']]\n","#     # Does the player we control have the ball?\n","#     if obs['ball_owned_player'] == obs['active'] and obs['ball_owned_team'] == 0:  #EXEI PAIKTIS TIN MPALA KAI EINAI STIN ARISTERI OMADA\n","#         # Shot if we are 'close' to the goal (based on 'x' coordinate).\n","#         if controlled_player_pos[0] > 0.5:\n","#             return Action.Shot\n","#         # Run towards the goal otherwise.\n","#         return Action.Right\n","#     else:\n","#         # Run towards the ball.\n","#         if obs['ball'][0] > controlled_player_pos[0] + 0.05:\n","#             return Action.Right\n","#         if obs['ball'][0] < controlled_player_pos[0] - 0.05:\n","#             return Action.Left\n","#         if obs['ball'][1] > controlled_player_pos[1] + 0.05:\n","#             return Action.Bottom\n","#         if obs['ball'][1] < controlled_player_pos[1] - 0.05:\n","#             return Action.Top\n","#         # Try to take over the ball if close to the ball.\n","#         return Action.Slide"],"metadata":{"id":"IgzLAAGcvOB0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Set up the Environment.\n","# from kaggle_environments import make\n","# env = make(\"football\", configuration={\"save_video\": True, \"scenario_name\": \"11_vs_11_kaggle\", \"running_in_notebook\": True})\n","# output = env.run([\"/kaggle/working/submission.py\", \"do_nothing\"])[-1]\n","# print('Left player: reward = %s, status = %s, info = %s' % (output[0]['reward'], output[0]['status'], output[0]['info']))\n","# print('Right player: reward = %s, status = %s, info = %s' % (output[1]['reward'], output[1]['status'], output[1]['info']))\n","# env.render(mode=\"human\", width=800, height=600)"],"metadata":{"id":"Ez73Yfd9vOZ2"},"execution_count":null,"outputs":[]}]}