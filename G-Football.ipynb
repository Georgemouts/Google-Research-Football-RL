{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"G-Football.ipynb","provenance":[],"collapsed_sections":["JezRCSzQzmyy"],"authorship_tag":"ABX9TyPz5M8V0P9ghWLlnhEMfA3s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"JezRCSzQzmyy"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"AwiPWSjbujSz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649351752763,"user_tz":-180,"elapsed":60881,"user":{"displayName":"george mouts","userId":"12301814581979843830"}},"outputId":"925a15e8-fab2-4c95-84a0-a82b8bc42189"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'kaggle-environments'...\n","remote: Enumerating objects: 4235, done.\u001b[K\n","remote: Counting objects: 100% (1015/1015), done.\u001b[K\n","remote: Compressing objects: 100% (323/323), done.\u001b[K\n","remote: Total 4235 (delta 812), reused 809 (delta 690), pack-reused 3220\u001b[K\n","Receiving objects: 100% (4235/4235), 11.38 MiB | 8.94 MiB/s, done.\n","Resolving deltas: 100% (2571/2571), done.\n","Processing /content/kaggle-environments\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.7) (4.3.3)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.7) (1.1.4)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from kaggle-environments==1.9.7) (1.21.5)\n","Collecting requests>=2.25.1\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.0 MB/s \n","\u001b[?25hRequirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (7.1.2)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (1.0.1)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (1.1.0)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->kaggle-environments==1.9.7) (2.11.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.2->kaggle-environments==1.9.7) (2.0.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (5.4.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (21.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (0.18.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (3.10.0.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments==1.9.7) (4.11.3)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.1->kaggle-environments==1.9.7) (3.7.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (1.24.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->kaggle-environments==1.9.7) (2.10)\n","Building wheels for collected packages: kaggle-environments\n","  Building wheel for kaggle-environments (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaggle-environments: filename=kaggle_environments-1.9.7-py3-none-any.whl size=1813048 sha256=cb75fae659b9db3d0894da24fadb823765f497742eb52645d4b6ce8b4577f25c\n","  Stored in directory: /root/.cache/pip/wheels/67/f1/54/59176bd30840c0a045df67632e2e903095b3c02b64cb0a636c\n","Successfully built kaggle-environments\n","Installing collected packages: requests, kaggle-environments\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed kaggle-environments-1.9.7 requests-2.27.1\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [82.3 kB]\n","Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [952 kB]\n","Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,831 kB]\n","Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,490 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,134 kB]\n","Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [884 kB]\n","Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,694 kB]\n","Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [938 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n","Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,268 kB]\n","Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [918 kB]\n","Get:27 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n","Get:28 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.9 kB]\n","Get:29 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.2 kB]\n","Get:30 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n","Fetched 15.6 MB in 4s (4,217 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  gir1.2-ibus-1.0 libcapnp-0.6.1 libdbus-1-dev libibus-1.0-5 libibus-1.0-dev\n","  libmirclient-dev libmirclient9 libmircommon-dev libmircommon7\n","  libmircookie-dev libmircookie2 libmircore-dev libmircore1 libmirprotobuf3\n","  libprotobuf-dev libprotobuf-lite10 libpulse-dev libpulse-mainloop-glib0\n","  libsdl2-dev libsdl2-gfx-1.0-0 libsdl2-ttf-2.0-0 libsndio-dev libudev-dev\n","  libxcursor-dev libxinerama-dev libxkbcommon-dev libxrandr-dev libxv-dev\n","  x11proto-randr-dev x11proto-xinerama-dev\n","Suggested packages:\n","  libsdl2-gfx-doc\n","The following NEW packages will be installed:\n","  gir1.2-ibus-1.0 libcapnp-0.6.1 libdbus-1-dev libibus-1.0-5 libibus-1.0-dev\n","  libmirclient-dev libmirclient9 libmircommon-dev libmircommon7\n","  libmircookie-dev libmircookie2 libmircore-dev libmircore1 libmirprotobuf3\n","  libprotobuf-dev libprotobuf-lite10 libpulse-dev libpulse-mainloop-glib0\n","  libsdl2-dev libsdl2-gfx-1.0-0 libsdl2-gfx-dev libsdl2-ttf-2.0-0\n","  libsdl2-ttf-dev libsndio-dev libudev-dev libxcursor-dev libxinerama-dev\n","  libxkbcommon-dev libxrandr-dev libxv-dev x11proto-randr-dev\n","  x11proto-xinerama-dev\n","0 upgraded, 32 newly installed, 0 to remove and 96 not upgraded.\n","Need to get 3,919 kB of archives.\n","After this operation, 24.9 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libibus-1.0-5 amd64 1.5.17-3ubuntu5.3 [133 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gir1.2-ibus-1.0 amd64 1.5.17-3ubuntu5.3 [66.5 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcapnp-0.6.1 amd64 0.6.1-1ubuntu1 [658 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdbus-1-dev amd64 1.12.2-1ubuntu1.2 [165 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libibus-1.0-dev amd64 1.5.17-3ubuntu5.3 [145 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore1 amd64 0.31.1-0ubuntu1 [26.5 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon7 amd64 0.31.1-0ubuntu1 [73.9 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-lite10 amd64 3.0.0-9.1ubuntu1 [97.7 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirprotobuf3 amd64 0.31.1-0ubuntu1 [127 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient9 amd64 0.31.1-0ubuntu1 [199 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircore-dev amd64 0.31.1-0ubuntu1 [21.7 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf-dev amd64 3.0.0-9.1ubuntu1 [959 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxkbcommon-dev amd64 0.8.2-1~ubuntu18.04.1 [150 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircommon-dev amd64 0.31.1-0ubuntu1 [13.9 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie2 amd64 0.31.1-0ubuntu1 [19.7 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmircookie-dev amd64 0.31.1-0ubuntu1 [4,392 B]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmirclient-dev amd64 0.31.1-0ubuntu1 [47.8 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-mainloop-glib0 amd64 1:11.1-1ubuntu7.11 [22.1 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpulse-dev amd64 1:11.1-1ubuntu7.11 [81.5 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsndio-dev amd64 1.1.0-3 [13.3 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libudev-dev amd64 237-3ubuntu10.53 [19.1 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor-dev amd64 1:1.1.15-1 [26.5 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xinerama-dev all 2018.4-4 [2,628 B]\n","Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama-dev amd64 2:1.1.3-1 [8,404 B]\n","Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-randr-dev all 2018.4-4 [2,620 B]\n","Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr-dev amd64 2:1.5.1-1 [24.0 kB]\n","Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxv-dev amd64 2:1.0.11-1 [32.5 kB]\n","Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsdl2-dev amd64 2.0.8+dfsg1-1ubuntu1.18.04.4 [683 kB]\n","Get:29 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-gfx-1.0-0 amd64 1.0.4+dfsg-1 [29.9 kB]\n","Get:30 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-gfx-dev amd64 1.0.4+dfsg-1 [29.8 kB]\n","Get:31 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-ttf-2.0-0 amd64 2.0.14+dfsg1-2 [14.8 kB]\n","Get:32 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsdl2-ttf-dev amd64 2.0.14+dfsg1-2 [19.7 kB]\n","Fetched 3,919 kB in 1s (2,924 kB/s)\n","Extracting templates from packages: 100%\n","Selecting previously unselected package libibus-1.0-5:amd64.\n","(Reading database ... 156210 files and directories currently installed.)\n","Preparing to unpack .../00-libibus-1.0-5_1.5.17-3ubuntu5.3_amd64.deb ...\n","Unpacking libibus-1.0-5:amd64 (1.5.17-3ubuntu5.3) ...\n","Selecting previously unselected package gir1.2-ibus-1.0:amd64.\n","Preparing to unpack .../01-gir1.2-ibus-1.0_1.5.17-3ubuntu5.3_amd64.deb ...\n","Unpacking gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu5.3) ...\n","Selecting previously unselected package libcapnp-0.6.1:amd64.\n","Preparing to unpack .../02-libcapnp-0.6.1_0.6.1-1ubuntu1_amd64.deb ...\n","Unpacking libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n","Selecting previously unselected package libdbus-1-dev:amd64.\n","Preparing to unpack .../03-libdbus-1-dev_1.12.2-1ubuntu1.2_amd64.deb ...\n","Unpacking libdbus-1-dev:amd64 (1.12.2-1ubuntu1.2) ...\n","Selecting previously unselected package libibus-1.0-dev:amd64.\n","Preparing to unpack .../04-libibus-1.0-dev_1.5.17-3ubuntu5.3_amd64.deb ...\n","Unpacking libibus-1.0-dev:amd64 (1.5.17-3ubuntu5.3) ...\n","Selecting previously unselected package libmircore1:amd64.\n","Preparing to unpack .../05-libmircore1_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircore1:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmircommon7:amd64.\n","Preparing to unpack .../06-libmircommon7_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libprotobuf-lite10:amd64.\n","Preparing to unpack .../07-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n","Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n","Selecting previously unselected package libmirprotobuf3:amd64.\n","Preparing to unpack .../08-libmirprotobuf3_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmirclient9:amd64.\n","Preparing to unpack .../09-libmirclient9_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmircore-dev:amd64.\n","Preparing to unpack .../10-libmircore-dev_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libprotobuf-dev:amd64.\n","Preparing to unpack .../11-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n","Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n","Selecting previously unselected package libxkbcommon-dev:amd64.\n","Preparing to unpack .../12-libxkbcommon-dev_0.8.2-1~ubuntu18.04.1_amd64.deb ...\n","Unpacking libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\n","Selecting previously unselected package libmircommon-dev:amd64.\n","Preparing to unpack .../13-libmircommon-dev_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmircookie2:amd64.\n","Preparing to unpack .../14-libmircookie2_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmircookie-dev:amd64.\n","Preparing to unpack .../15-libmircookie-dev_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libmirclient-dev:amd64.\n","Preparing to unpack .../16-libmirclient-dev_0.31.1-0ubuntu1_amd64.deb ...\n","Unpacking libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n","Selecting previously unselected package libpulse-mainloop-glib0:amd64.\n","Preparing to unpack .../17-libpulse-mainloop-glib0_1%3a11.1-1ubuntu7.11_amd64.deb ...\n","Unpacking libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.11) ...\n","Selecting previously unselected package libpulse-dev:amd64.\n","Preparing to unpack .../18-libpulse-dev_1%3a11.1-1ubuntu7.11_amd64.deb ...\n","Unpacking libpulse-dev:amd64 (1:11.1-1ubuntu7.11) ...\n","Selecting previously unselected package libsndio-dev:amd64.\n","Preparing to unpack .../19-libsndio-dev_1.1.0-3_amd64.deb ...\n","Unpacking libsndio-dev:amd64 (1.1.0-3) ...\n","Selecting previously unselected package libudev-dev:amd64.\n","Preparing to unpack .../20-libudev-dev_237-3ubuntu10.53_amd64.deb ...\n","Unpacking libudev-dev:amd64 (237-3ubuntu10.53) ...\n","Selecting previously unselected package libxcursor-dev:amd64.\n","Preparing to unpack .../21-libxcursor-dev_1%3a1.1.15-1_amd64.deb ...\n","Unpacking libxcursor-dev:amd64 (1:1.1.15-1) ...\n","Selecting previously unselected package x11proto-xinerama-dev.\n","Preparing to unpack .../22-x11proto-xinerama-dev_2018.4-4_all.deb ...\n","Unpacking x11proto-xinerama-dev (2018.4-4) ...\n","Selecting previously unselected package libxinerama-dev:amd64.\n","Preparing to unpack .../23-libxinerama-dev_2%3a1.1.3-1_amd64.deb ...\n","Unpacking libxinerama-dev:amd64 (2:1.1.3-1) ...\n","Selecting previously unselected package x11proto-randr-dev.\n","Preparing to unpack .../24-x11proto-randr-dev_2018.4-4_all.deb ...\n","Unpacking x11proto-randr-dev (2018.4-4) ...\n","Selecting previously unselected package libxrandr-dev:amd64.\n","Preparing to unpack .../25-libxrandr-dev_2%3a1.5.1-1_amd64.deb ...\n","Unpacking libxrandr-dev:amd64 (2:1.5.1-1) ...\n","Selecting previously unselected package libxv-dev:amd64.\n","Preparing to unpack .../26-libxv-dev_2%3a1.0.11-1_amd64.deb ...\n","Unpacking libxv-dev:amd64 (2:1.0.11-1) ...\n","Selecting previously unselected package libsdl2-dev:amd64.\n","Preparing to unpack .../27-libsdl2-dev_2.0.8+dfsg1-1ubuntu1.18.04.4_amd64.deb ...\n","Unpacking libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\n","Selecting previously unselected package libsdl2-gfx-1.0-0:amd64.\n","Preparing to unpack .../28-libsdl2-gfx-1.0-0_1.0.4+dfsg-1_amd64.deb ...\n","Unpacking libsdl2-gfx-1.0-0:amd64 (1.0.4+dfsg-1) ...\n","Selecting previously unselected package libsdl2-gfx-dev:amd64.\n","Preparing to unpack .../29-libsdl2-gfx-dev_1.0.4+dfsg-1_amd64.deb ...\n","Unpacking libsdl2-gfx-dev:amd64 (1.0.4+dfsg-1) ...\n","Selecting previously unselected package libsdl2-ttf-2.0-0:amd64.\n","Preparing to unpack .../30-libsdl2-ttf-2.0-0_2.0.14+dfsg1-2_amd64.deb ...\n","Unpacking libsdl2-ttf-2.0-0:amd64 (2.0.14+dfsg1-2) ...\n","Selecting previously unselected package libsdl2-ttf-dev:amd64.\n","Preparing to unpack .../31-libsdl2-ttf-dev_2.0.14+dfsg1-2_amd64.deb ...\n","Unpacking libsdl2-ttf-dev:amd64 (2.0.14+dfsg1-2) ...\n","Setting up libdbus-1-dev:amd64 (1.12.2-1ubuntu1.2) ...\n","Setting up libxcursor-dev:amd64 (1:1.1.15-1) ...\n","Setting up libxkbcommon-dev:amd64 (0.8.2-1~ubuntu18.04.1) ...\n","Setting up libsdl2-gfx-1.0-0:amd64 (1.0.4+dfsg-1) ...\n","Setting up libpulse-mainloop-glib0:amd64 (1:11.1-1ubuntu7.11) ...\n","Setting up libpulse-dev:amd64 (1:11.1-1ubuntu7.11) ...\n","Setting up libmircore-dev:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libsndio-dev:amd64 (1.1.0-3) ...\n","Setting up libmircookie2:amd64 (0.31.1-0ubuntu1) ...\n","Setting up x11proto-xinerama-dev (2018.4-4) ...\n","Setting up x11proto-randr-dev (2018.4-4) ...\n","Setting up libxinerama-dev:amd64 (2:1.1.3-1) ...\n","Setting up libxv-dev:amd64 (2:1.0.11-1) ...\n","Setting up libcapnp-0.6.1:amd64 (0.6.1-1ubuntu1) ...\n","Setting up libibus-1.0-5:amd64 (1.5.17-3ubuntu5.3) ...\n","Setting up libsdl2-ttf-2.0-0:amd64 (2.0.14+dfsg1-2) ...\n","Setting up libmircore1:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n","Setting up libudev-dev:amd64 (237-3ubuntu10.53) ...\n","Setting up gir1.2-ibus-1.0:amd64 (1.5.17-3ubuntu5.3) ...\n","Setting up libxrandr-dev:amd64 (2:1.5.1-1) ...\n","Setting up libmirprotobuf3:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n","Setting up libmircookie-dev:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libibus-1.0-dev:amd64 (1.5.17-3ubuntu5.3) ...\n","Setting up libmircommon7:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libmirclient9:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libmircommon-dev:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libmirclient-dev:amd64 (0.31.1-0ubuntu1) ...\n","Setting up libsdl2-dev:amd64 (2.0.8+dfsg1-1ubuntu1.18.04.4) ...\n","Setting up libsdl2-ttf-dev:amd64 (2.0.14+dfsg1-2) ...\n","Setting up libsdl2-gfx-dev:amd64 (1.0.4+dfsg-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Cloning into 'football'...\n","remote: Enumerating objects: 2908, done.\u001b[K\n","remote: Counting objects: 100% (36/36), done.\u001b[K\n","remote: Compressing objects: 100% (22/22), done.\u001b[K\n","remote: Total 2908 (delta 10), reused 23 (delta 7), pack-reused 2872\u001b[K\n","Receiving objects: 100% (2908/2908), 27.11 MiB | 21.74 MiB/s, done.\n","Resolving deltas: 100% (1653/1653), done.\n","--2022-04-07 17:15:32--  https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.8.so\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.12.128, 108.177.13.128, 74.125.26.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.12.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 45403632 (43M) [application/octet-stream]\n","Saving to: ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’\n","\n","football/third_part 100%[===================>]  43.30M   127MB/s    in 0.3s    \n","\n","2022-04-07 17:15:33 (127 MB/s) - ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’ saved [45403632/45403632]\n","\n","Processing /content/football\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting pygame==1.9.6\n","  Downloading pygame-1.9.6-cp37-cp37m-manylinux1_x86_64.whl (11.4 MB)\n","\u001b[K     |████████████████████████████████| 11.4 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (4.1.2.30)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (1.4.1)\n","Requirement already satisfied: gym>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (0.17.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (1.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from gfootball==2.8) (0.37.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.21.5)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.3.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.8) (1.5.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.11.0->gfootball==2.8) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->gfootball==2.8) (1.15.0)\n","Building wheels for collected packages: gfootball\n","  Building wheel for gfootball (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gfootball: filename=gfootball-2.8-cp37-cp37m-linux_x86_64.whl size=38781744 sha256=4cbf35e5595ac76831eddac0ad21320d77fe3a2f2583afceae3e3e472a3fd5cc\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8h2kvcp0/wheels/bb/c2/92/82a23d0c207f5497a23f4316675eb1629e6be474bd2c3be61a\n","Successfully built gfootball\n","Installing collected packages: pygame, gfootball\n","Successfully installed gfootball-2.8 pygame-1.9.6\n"]}],"source":["#https://www.kaggle.com/piotrstanczyk/gfootball-template-bot  G-FOOTBALL TEMPLATE BOT\n","# Install:\n","# Kaggle environments.\n","!git clone https://github.com/Kaggle/kaggle-environments.git\n","!cd kaggle-environments && pip install .\n","\n","# GFootball environment.\n","!apt-get update -y\n","!apt-get install -y libsdl2-gfx-dev libsdl2-ttf-dev\n","\n","# Make sure that the Branch in git clone and in wget call matches !!\n","!git clone -b v2.8 https://github.com/google-research/football.git\n","!mkdir -p football/third_party/gfootball_engine/lib\n","\n","!wget https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.8.so -O football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so\n","!cd football && GFOOTBALL_USE_PREBUILT_SO=1 pip3 install ."]},{"cell_type":"markdown","source":["# All the imports"],"metadata":{"id":"WVKirdPZ7joO"}},{"cell_type":"code","source":["from gfootball.env.football_env import FootballEnv\n","from kaggle_environments import make\n","from gfootball.env.config import Config\n","from gfootball.env.football_env import FootballEnv\n","\n","#import dqn libraries\n","import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim \n","import numpy as np\n","import pandas as pd\n","import itertools\n","import random\n","from collections import deque\n","import matplotlib.pyplot as plt\n","\n","#import env \n","import gym\n","import gfootball \n","\n","#env_name = \"GFootballBase-v0\"\n","#print(env_name)"],"metadata":{"id":"Y8iVn65JzVqw","executionInfo":{"status":"ok","timestamp":1649352360615,"user_tz":-180,"elapsed":3,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Initialize variables"],"metadata":{"id":"6DnksAK4BzPW"}},{"cell_type":"code","source":["BUFFERSIZE = 100000  #how many experiences will store |ReplayBufferSize=100,000\n","REWBUFFERSIZE = 100   #how many episode rewards will store|RewardBufferSize =100\n","MINREPLAYSIZE= 3000 # Episode is 3000 steps\n","GAMMA = 0.04\n","EPSILON =0.03\n","TARGET_UPDATE_FREQ = 25\n","\n","EPSILON_START=0.5\n","EPSILON_END =0.01\n","EPSILON_DECAY=0.001\n","\n","BATCH_SIZE = 3\n"],"metadata":{"id":"Q1ygyd2KEjM2","executionInfo":{"status":"ok","timestamp":1649352361744,"user_tz":-180,"elapsed":4,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Deep Q Network Model"],"metadata":{"id":"xTTdFh2aEFjF"}},{"cell_type":"code","source":["class DQN(nn.Module):\n","  def __init__(self,env):\n","    super(DQN,self).__init__()\n","    input_dims = int(np.prod(env.observation_space.shape)) #neurons input layer = number of observations\n","    self.net =nn.Sequential(nn.Linear(input_dims,200), \n","                            nn.Tanh(),\n","                            nn.Linear(200,env.action_space.n)) # neurons outpul layer = number of observations \n","                            \n","  def forward(self,x):\n","    return self.net(x) #use the dqnetwork\n","\n","  def act(self,obs): #returns the best acrtion/highest value action of the net \n","    obs_t =torch.as_tensor(obs,dtype=torch.float32)\n","    q_values=self(obs_t.unsqueeze(0)) # make tensor a batch dimension\n","\n","    max_q_index = torch.argmax(q_values,dim=1)[0]   # taking action with highest q value\n","    action = max_q_index.detach().item() # making tensor to integer which represents action \n","    \n","    return action \n","\n"],"metadata":{"id":"to44sPKhEETf","executionInfo":{"status":"ok","timestamp":1649352363230,"user_tz":-180,"elapsed":8,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Agent "],"metadata":{"id":"Elknm2VGEhMX"}},{"cell_type":"code","source":["class Agent() : \n","  def __init__(self,gamma,epsilon):\n","    self.gamma =gamma\n","    self.epsilon =epsilon\n","    \n","    self.ReplayBuffer = deque(maxlen=BUFFERSIZE) #Store experiences \n","    self.RewBuffer = deque(maxlen=REWBUFFERSIZE) #Store rewards\n","    \n","    self.online_net = DQN(env)   \n","    self.target_net = DQN(env)  \n","\n","    self.target_net.load_state_dict(self.online_net.state_dict())\n","\n","\n","  def transition(self,obs,new_obs,action,reward ,done): # should be tuple ? \n","    self.obs =obs\n","    self.action=action\n","    self.reward =reward \n","    self.done=done\n","    #self.info =info\n","    self.new_obs =new_obs\n","    TransitionTuple= (obs,new_obs,action,reward,done)\n","    #print(\"class\",TransitionTuple)\n","    return TransitionTuple\n","\n","  def learn(self,optimizer):\n","    self.optimizer=torch.optim.Adam(self.online_net.parameters(),lr =1e-3) \n","    \n"],"metadata":{"id":"1IRll4ZoEi7c","executionInfo":{"status":"ok","timestamp":1649352363528,"user_tz":-180,"elapsed":4,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"knTlNNXLoR_n","executionInfo":{"status":"ok","timestamp":1649352363860,"user_tz":-180,"elapsed":9,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"I7CxKikMoSgK","executionInfo":{"status":"ok","timestamp":1649352364451,"user_tz":-180,"elapsed":10,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# All Prints"],"metadata":{"id":"2MA4EXOMYaII"}},{"cell_type":"code","source":["class All_prints():\n","  \n","  def __init___(self,step):\n","    self.step=step\n","    #self.RewBuffer = RewBuffer\n","    self.reward=reward\n","\n","  def printstats(self,step,RewBuffer,eps_reward):  #Kaleitai otan ginei done , diladi otan teleiosei ena paixnidi\n","    self.step=step\n","    self.RewBuffer=RewBuffer\n","    self.eps_reward=eps_reward\n","    print(\"-->Episode:\",self.step%3000 + 1 ,\"\\t\",\"Episode Reward:\",self.eps_reward,\"<--\")\n","    print(\"Step\",step)\n","    print(\"lista apo rewards mexri tora\" ,self.RewBuffer)\n","    print(\"Avg reward\", np.mean(self.RewBuffer))\n","    print(\"---------------------------------------------------\")\n","\n","  def print_who_scored(self, reward):\n","    self.reward=reward\n","    if(self.reward==-1):\n","      print(\"opponent team scored\")\n","    elif(self.reward==1):\n","      print(\"our team scored !!!\")\n"," \n","  def rew_graph(self,RewBuffer,step,num_of_eps):\n","      self.RewBuffer=RewBuffer\n","      self.step=step\n","      self.num_of_eps=num_of_eps\n","\n","      episode=self.step%3000\n","      eps_list=list(range(1,self.num_of_eps+1))#pairnei to proto , den pairnei to teleytaio\n","      #print(agent.RewBuffer,eps_list)\n","      plt.plot(eps_list,self.RewBuffer)\n","      plt.xlabel('Episode')\n","      plt.ylabel('Rewards')\n","      plt.grid(True)\n","      plt.show()"],"metadata":{"id":"9kC3LFnSmkGC","executionInfo":{"status":"ok","timestamp":1649352365221,"user_tz":-180,"elapsed":5,"user":{"displayName":"george mouts","userId":"12301814581979843830"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Create Environment -- Main \n"],"metadata":{"id":"ZCAOuUjA8ZpZ"}},{"cell_type":"code","source":["#if __name__ =='main': \n","\n","#TO DO : MAKE REPLAY BUFFER A CLASS\n","#TO DO:MAKE A CLASS FOR LEARNING\n","\n","env = gym.make(\"GFootball-11_vs_11_kaggle-simple115v2-v0\") #List with the 115 states \n","eps_reward =0.0\n","\n","obs = env.reset()\n","\n","#CREATE OBJECTS \n","agent=Agent(GAMMA,EPSILON) #Agent class\n","all_prints=All_prints() # print class\n","\n","#Initialize ReplayBuffer # TO DO : MAKE IT A CLASS\n","for i in range(MINREPLAYSIZE): \n","  action =env.action_space.sample() #random action \n","\n","  new_obs ,reward,done ,info = env.step(action) \n","\n","  transition = agent.transition(obs,new_obs,action,reward ,done) #obs ,action ,reward , done ,info , new_obs  PROSEKSE TO MALLON LATHOS\n","  agent.ReplayBuffer.append(transition)  #Fill Replay Buffer with transitions\n","  obs=new_obs\n","\n"," \n","  if(done):  # if someone score  a goal reset the env \n","    obs=env.reset()\n","\n","\n","# MAIN TRAIN LOOP\n","obs =env.reset()\n","c= 0\n","num_of_eps= 50     #GIVE NUMBER OF EPISODES\n","\n","for step in range((3000 * num_of_eps) + num_of_eps ):# play 3000 steps = 1 match = 1 episode\n","  \n","  \n","  #epsilon greedy\n","  epsilon = np.interp(step,[0,EPSILON_DECAY],[EPSILON_START,EPSILON_END]) #Epsilon start->end with epsilon decays steps from 100% random actions->2% rnd actions\n","  rnd_sample = random.random()\n","  \n","  if rnd_sample <= epsilon: #random action |explore|\n","    action = env.action_space.sample()\n","  else:  \n","    action = agent.online_net.act(obs) #best action |exploit|     YPARXEI THEMA EDO PERA , POU GEMIZEI TO ONLINE NET ??\n","# return action \n","  \n","  \n","  \n","  new_obs,reward,done,info = env.step(action)\n","\n","  all_prints.print_who_scored(reward)\n","\n","  transition = agent.transition(obs,new_obs,action,reward ,done) #fill Replaybuffer with transitions \n","\n","  agent.ReplayBuffer.append(transition) # To Replay Buffer gemizei kanonika\n","  obs=new_obs\n","\n","  eps_reward = eps_reward+reward\n","  #print(\"eps_reward:\",eps_reward,\"rew:\",reward,info,done)\n","\n","  if (done) :\n","    \n","    obs=env.reset()\n","   \n","    agent.RewBuffer.append(eps_reward)\n","\n","    #Print Resume when an episode ends \n","    all_prints.printstats(step,agent.RewBuffer,eps_reward)\n","    #print(step)\n","    if(step == (3000 * num_of_eps)+num_of_eps -1):\n","       \n","      all_prints.rew_graph(agent.RewBuffer,step,num_of_eps)\n","    \n","    eps_reward =0.0 \n","\n","\n","# Start Gradient Step \n","  transitions =random.sample(agent.ReplayBuffer , BATCH_SIZE) #sample batch_size number of random transitions from Replaybuffer ,\n","                                                              # Replay buffer have been filled earlier\n"," #Store convert -> return pytorch tensors \n","  #Store observations as arrays\n","  obses = np.asarray([t[0] for t in transitions])\n","  new_obses = np.asarray([t[1]for t in transitions])\n","  actions = np.asarray([t[2] for t in transitions])\n","  rewards = np.asarray([t[3] for t in transitions])\n","  dones = np.asarray([t[4] for t in transitions])\n","  \n","  #Convert observation arrays to pytorch tensors\n","  obses_t=torch.as_tensor(obses,dtype=torch.float32)\n","  actions_t = torch.as_tensor(actions,dtype=torch.int64).unsqueeze(-1) #making batch dimension to one dimension\n","  rewards_t = torch.as_tensor(rewards,dtype= torch.float32).unsqueeze(-1)\n","  dones_t = torch.as_tensor(dones,dtype= torch.float32).unsqueeze(-1)\n","  new_obses_t = torch.as_tensor(new_obses,dtype= torch.float32)\n","\n","\n","  #Compute Targets\n","  \n","  target_q_values = agent.target_net(new_obses_t)# q values for each observation \n","  max_target_q_values = target_q_values.max(dim=1,keepdim=True)[0] #take the maximum value in dim =1 , discard all the rest dimensions\n","                                                                  #max returns tuple , first element is highest values and second is the index to them \n","\n","  targets = rewards_t +GAMMA + (1-dones_t) * max_target_q_values #deepmind_atari_paper dqn learn with replay\n","                                                                #if its a terminal state: dones_t =1 -> targets= rewards_t\n","\n","  #Compute Loss\n","  q_values = agent.online_net(obses_t)\n","  action_q_values =torch.gather(input=q_values,dim=1,index=actions_t)\n","  loss=nn.functional.smooth_l1_loss(action_q_values,targets)\n","\n","  #Gradient Descent -> NA MPEI SE SYNARTHSH LEARN TOU AGENT \n","  optimizer=torch.optim.Adam(agent.online_net.parameters(),lr =0.02)\n","  #print(optimizer)\n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()\n","\n","  #Update the target network, copying all weights and biases in DQN\n","  if step% TARGET_UPDATE_FREQ == 0:   #Update target network based on online network\n","    agent.target_net.load_state_dict(agent.online_net.state_dict())\n","\n","  \n","  \n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Elq8YWsx8d1C","executionInfo":{"status":"ok","timestamp":1649354440171,"user_tz":-180,"elapsed":2073507,"user":{"displayName":"george mouts","userId":"12301814581979843830"}},"outputId":"fce016eb-77ba-4bf2-c09f-3f4f59066d15"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 1 \t Episode Reward: -5.0 <--\n","Step 3000\n","lista apo rewards mexri tora deque([-5.0], maxlen=100)\n","Avg reward -5.0\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 2 \t Episode Reward: -1.0 <--\n","Step 6001\n","lista apo rewards mexri tora deque([-5.0, -1.0], maxlen=100)\n","Avg reward -3.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 3 \t Episode Reward: -4.0 <--\n","Step 9002\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0], maxlen=100)\n","Avg reward -3.3333333333333335\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 4 \t Episode Reward: -3.0 <--\n","Step 12003\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0], maxlen=100)\n","Avg reward -3.25\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 5 \t Episode Reward: -2.0 <--\n","Step 15004\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0], maxlen=100)\n","Avg reward -3.0\n","---------------------------------------------------\n","-->Episode: 6 \t Episode Reward: 0.0 <--\n","Step 18005\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0], maxlen=100)\n","Avg reward -2.5\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 7 \t Episode Reward: -1.0 <--\n","Step 21006\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0], maxlen=100)\n","Avg reward -2.2857142857142856\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 8 \t Episode Reward: -1.0 <--\n","Step 24007\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0], maxlen=100)\n","Avg reward -2.125\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 9 \t Episode Reward: -2.0 <--\n","Step 27008\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0], maxlen=100)\n","Avg reward -2.111111111111111\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 10 \t Episode Reward: -2.0 <--\n","Step 30009\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0], maxlen=100)\n","Avg reward -2.1\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 11 \t Episode Reward: -1.0 <--\n","Step 33010\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0], maxlen=100)\n","Avg reward -2.0\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 12 \t Episode Reward: -7.0 <--\n","Step 36011\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0], maxlen=100)\n","Avg reward -2.4166666666666665\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 13 \t Episode Reward: -5.0 <--\n","Step 39012\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0], maxlen=100)\n","Avg reward -2.6153846153846154\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 14 \t Episode Reward: -4.0 <--\n","Step 42013\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0], maxlen=100)\n","Avg reward -2.7142857142857144\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 15 \t Episode Reward: -3.0 <--\n","Step 45014\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0], maxlen=100)\n","Avg reward -2.7333333333333334\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 16 \t Episode Reward: -2.0 <--\n","Step 48015\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.6875\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 17 \t Episode Reward: -2.0 <--\n","Step 51016\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0], maxlen=100)\n","Avg reward -2.6470588235294117\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 18 \t Episode Reward: -5.0 <--\n","Step 54017\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0], maxlen=100)\n","Avg reward -2.7777777777777777\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 19 \t Episode Reward: -4.0 <--\n","Step 57018\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0], maxlen=100)\n","Avg reward -2.8421052631578947\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 20 \t Episode Reward: -3.0 <--\n","Step 60019\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0], maxlen=100)\n","Avg reward -2.85\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 21 \t Episode Reward: -3.0 <--\n","Step 63020\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0], maxlen=100)\n","Avg reward -2.857142857142857\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 22 \t Episode Reward: -4.0 <--\n","Step 66021\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0], maxlen=100)\n","Avg reward -2.909090909090909\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 23 \t Episode Reward: -2.0 <--\n","Step 69022\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0], maxlen=100)\n","Avg reward -2.869565217391304\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 24 \t Episode Reward: -4.0 <--\n","Step 72023\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0], maxlen=100)\n","Avg reward -2.9166666666666665\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 25 \t Episode Reward: -1.0 <--\n","Step 75024\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0], maxlen=100)\n","Avg reward -2.84\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 26 \t Episode Reward: -4.0 <--\n","Step 78025\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0], maxlen=100)\n","Avg reward -2.8846153846153846\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 27 \t Episode Reward: -1.0 <--\n","Step 81026\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0], maxlen=100)\n","Avg reward -2.814814814814815\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 28 \t Episode Reward: -3.0 <--\n","Step 84027\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0], maxlen=100)\n","Avg reward -2.8214285714285716\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 29 \t Episode Reward: -1.0 <--\n","Step 87028\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0], maxlen=100)\n","Avg reward -2.7586206896551726\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 30 \t Episode Reward: -1.0 <--\n","Step 90029\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0], maxlen=100)\n","Avg reward -2.7\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 31 \t Episode Reward: -5.0 <--\n","Step 93030\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0], maxlen=100)\n","Avg reward -2.774193548387097\n","---------------------------------------------------\n","-->Episode: 32 \t Episode Reward: 0.0 <--\n","Step 96031\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0], maxlen=100)\n","Avg reward -2.6875\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 33 \t Episode Reward: -2.0 <--\n","Step 99032\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0], maxlen=100)\n","Avg reward -2.6666666666666665\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 34 \t Episode Reward: -3.0 <--\n","Step 102033\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0], maxlen=100)\n","Avg reward -2.676470588235294\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 35 \t Episode Reward: -2.0 <--\n","Step 105034\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0], maxlen=100)\n","Avg reward -2.657142857142857\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 36 \t Episode Reward: -1.0 <--\n","Step 108035\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0], maxlen=100)\n","Avg reward -2.611111111111111\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 37 \t Episode Reward: -2.0 <--\n","Step 111036\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0], maxlen=100)\n","Avg reward -2.5945945945945947\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 38 \t Episode Reward: -6.0 <--\n","Step 114037\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0], maxlen=100)\n","Avg reward -2.6842105263157894\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 39 \t Episode Reward: -4.0 <--\n","Step 117038\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0], maxlen=100)\n","Avg reward -2.717948717948718\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 40 \t Episode Reward: -3.0 <--\n","Step 120039\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0, -3.0], maxlen=100)\n","Avg reward -2.725\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 41 \t Episode Reward: -1.0 <--\n","Step 123040\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0, -3.0, -1.0], maxlen=100)\n","Avg reward -2.682926829268293\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 42 \t Episode Reward: -2.0 <--\n","Step 126041\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0, -3.0, -1.0, -2.0], maxlen=100)\n","Avg reward -2.6666666666666665\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 43 \t Episode Reward: -5.0 <--\n","Step 129042\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0, -3.0, -1.0, -2.0, -5.0], maxlen=100)\n","Avg reward -2.7209302325581395\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 44 \t Episode Reward: -3.0 <--\n","Step 132043\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0, -3.0, -1.0, -2.0, -5.0, -3.0], maxlen=100)\n","Avg reward -2.727272727272727\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 45 \t Episode Reward: -3.0 <--\n","Step 135044\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0, -3.0, -1.0, -2.0, -5.0, -3.0, -3.0], maxlen=100)\n","Avg reward -2.7333333333333334\n","---------------------------------------------------\n","opponent team scored\n","-->Episode: 46 \t Episode Reward: -1.0 <--\n","Step 138045\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0, -3.0, -1.0, -2.0, -5.0, -3.0, -3.0, -1.0], maxlen=100)\n","Avg reward -2.6956521739130435\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 47 \t Episode Reward: -2.0 <--\n","Step 141046\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0, -3.0, -1.0, -2.0, -5.0, -3.0, -3.0, -1.0, -2.0], maxlen=100)\n","Avg reward -2.6808510638297873\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","-->Episode: 48 \t Episode Reward: -2.0 <--\n","Step 144047\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0, -3.0, -1.0, -2.0, -5.0, -3.0, -3.0, -1.0, -2.0, -2.0], maxlen=100)\n","Avg reward -2.6666666666666665\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 49 \t Episode Reward: -4.0 <--\n","Step 147048\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0, -3.0, -1.0, -2.0, -5.0, -3.0, -3.0, -1.0, -2.0, -2.0, -4.0], maxlen=100)\n","Avg reward -2.693877551020408\n","---------------------------------------------------\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","opponent team scored\n","-->Episode: 50 \t Episode Reward: -7.0 <--\n","Step 150049\n","lista apo rewards mexri tora deque([-5.0, -1.0, -4.0, -3.0, -2.0, 0.0, -1.0, -1.0, -2.0, -2.0, -1.0, -7.0, -5.0, -4.0, -3.0, -2.0, -2.0, -5.0, -4.0, -3.0, -3.0, -4.0, -2.0, -4.0, -1.0, -4.0, -1.0, -3.0, -1.0, -1.0, -5.0, 0.0, -2.0, -3.0, -2.0, -1.0, -2.0, -6.0, -4.0, -3.0, -1.0, -2.0, -5.0, -3.0, -3.0, -1.0, -2.0, -2.0, -4.0, -7.0], maxlen=100)\n","Avg reward -2.78\n","---------------------------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# obs = env.reset()\n","# a = env.step(action)\n","# print(obs ,'\\n New obs:',a)"],"metadata":{"id":"5fAsyCUrleeY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# env = make(\"football\", debug=True, configuration={\"save_video\": False, \"scenario_name\": \"11_vs_11_kaggle\", \"running_in_notebook\": True})\n","# env.render"],"metadata":{"id":"r58vLy9MzVKE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ena =env.reset() \n","# #dyo=simple_env.reset()\n","\n","# #print(ena.shape)\n","# print(ena[0])#olo to environment\n","# #pprint.pprint(ena[0])\n"],"metadata":{"id":"wMG5tesrzU6V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %%writefile submission.py\n","# from kaggle_environments.envs.football.helpers import *\n","\n","# ## @human_readable_agent wrapper modifies raw observations \n","# # provided by the environment:\n","# # https://github.com/google-research/football/blob/master/gfootball/doc/observation.md#raw-observations\n","# # into a form easier to work with by humans.\n","# # Following modifications are applied:\n","# # - Action, PlayerRole and GameMode enums are introduced.\n","# # - 'sticky_actions' are turned into a set of active actions (Action enum)\n","# #    see usage example below.\n","# # - 'game_mode' is turned into GameMode enum.\n","# # - 'designated' field is removed, as it always equals to 'active'\n","# #    when a single player is controlled on the team.\n","# # - 'left_team_roles'/'right_team_roles' are turned into PlayerRole enums.\n","# # - Action enum is to be returned by the agent function.\n","# @human_readable_agent\n","# def agent(obs):\n","#     # Make sure player is running.\n","#     if Action.Sprint not in obs['sticky_actions']:\n","#         return Action.Sprint\n","#     # We always control left team (observations and actions\n","#     # are mirrored appropriately by the environment).\n","#     controlled_player_pos = obs['left_team'][obs['active']]\n","#     # Does the player we control have the ball?\n","#     if obs['ball_owned_player'] == obs['active'] and obs['ball_owned_team'] == 0:  #EXEI PAIKTIS TIN MPALA KAI EINAI STIN ARISTERI OMADA\n","#         # Shot if we are 'close' to the goal (based on 'x' coordinate).\n","#         if controlled_player_pos[0] > 0.5:\n","#             return Action.Shot\n","#         # Run towards the goal otherwise.\n","#         return Action.Right\n","#     else:\n","#         # Run towards the ball.\n","#         if obs['ball'][0] > controlled_player_pos[0] + 0.05:\n","#             return Action.Right\n","#         if obs['ball'][0] < controlled_player_pos[0] - 0.05:\n","#             return Action.Left\n","#         if obs['ball'][1] > controlled_player_pos[1] + 0.05:\n","#             return Action.Bottom\n","#         if obs['ball'][1] < controlled_player_pos[1] - 0.05:\n","#             return Action.Top\n","#         # Try to take over the ball if close to the ball.\n","#         return Action.Slide"],"metadata":{"id":"IgzLAAGcvOB0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Set up the Environment.\n","# from kaggle_environments import make\n","# env = make(\"football\", configuration={\"save_video\": True, \"scenario_name\": \"11_vs_11_kaggle\", \"running_in_notebook\": True})\n","# output = env.run([\"/kaggle/working/submission.py\", \"do_nothing\"])[-1]\n","# print('Left player: reward = %s, status = %s, info = %s' % (output[0]['reward'], output[0]['status'], output[0]['info']))\n","# print('Right player: reward = %s, status = %s, info = %s' % (output[1]['reward'], output[1]['status'], output[1]['info']))\n","# env.render(mode=\"human\", width=800, height=600)"],"metadata":{"id":"Ez73Yfd9vOZ2"},"execution_count":null,"outputs":[]}]}